<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName JATS-archivearticle1.dtd?><?SourceDTD.Version 1.1?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">4016241</article-id><article-id pub-id-type="pmid">24816822</article-id><article-id pub-id-type="publisher-id">PONE-D-13-53218</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0097079</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Biology and Life Sciences</subject><subj-group><subject>Computational Biology</subject><subj-group><subject>Genome Analysis</subject><subj-group><subject>Genetic Networks</subject></subj-group></subj-group></subj-group><subj-group><subject>Genetics</subject><subj-group><subject>Genetics of Disease</subject></subj-group></subj-group><subj-group><subject>Systems Biology</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Computer and Information Sciences</subject><subj-group><subject>Computerized Simulations</subject></subj-group><subj-group><subject>Computer Modeling</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Applied Mathematics</subject><subj-group><subject>Algorithms</subject></subj-group></subj-group></subj-group></subj-group></article-categories><title-group><article-title><SecTag type="TITLE"><text><SENT sid="0" pm="."><plain>Ensemble Positive Unlabeled Learning for Disease Gene Identification </plain></SENT>
</text></SecTag></article-title><alt-title alt-title-type="running-head">Ensemble PU Learning for Disease Gene Prediction</alt-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Yang</surname><given-names>Peng</given-names></name><xref ref-type="aff" rid="aff1">
<sup>1</sup>
</xref><xref ref-type="corresp" rid="cor1">
<sup>*</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Li</surname><given-names>Xiaoli</given-names></name><xref ref-type="aff" rid="aff1">
<sup>1</sup>
</xref><xref ref-type="corresp" rid="cor1">
<sup>*</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Chua</surname><given-names>Hon-Nian</given-names></name><xref ref-type="aff" rid="aff1">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Kwoh</surname><given-names>Chee-Keong</given-names></name><xref ref-type="aff" rid="aff2">
<sup>2</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Ng</surname><given-names>See-Kiong</given-names></name><xref ref-type="aff" rid="aff1">
<sup>1</sup>
</xref></contrib></contrib-group><aff id="aff1">
<label>1</label>
<addr-line>Data Analytics Department, Institute for Infocomm Research (I2R), Agency for Science, Technology and Research (A*STAR), Singapore, Singapore</addr-line>
</aff><aff id="aff2">
<label>2</label>
<addr-line>Bioinformatics Research Centre, School of Computer Engineering, Nanyang Technological University, Singapore, Singapore</addr-line>
</aff><contrib-group><contrib contrib-type="editor"><name><surname>Hernandez-Lemus</surname><given-names>Enrique</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1">
<addr-line>National Institute of Genomic Medicine, Mexico</addr-line>
</aff><author-notes><corresp id="cor1">* E-mail: <email>yangp@i2r.a-star.edu.sg</email> (PY); <email>xlli@i2r.a-star.edu.sg</email> (XL)</corresp><fn fn-type="COI-statement"><p><text><SENT sid="1" pm="."><plain>Competing Interests: The authors have declared that no competing interests exist. </plain></SENT>
</text></p></fn><fn fn-type="con"><p><text><SENT sid="2" pm="."><plain>Conceived and designed the experiments: PY XL. </plain></SENT>
<SENT sid="3" pm="."><plain>Performed the experiments: PY. </plain></SENT>
<SENT sid="4" pm="."><plain>Analyzed the data: PY H-NC. </plain></SENT>
<SENT sid="5" pm="."><plain>Contributed reagents/materials/analysis tools: H-NC. </plain></SENT>
<SENT sid="6" pm="."><plain>Wrote the paper: PY XL. </plain></SENT>
<SENT sid="7" pm="."><plain>Participated in discussion and improved the method as well as revised the draft: C-KK S-KN. </plain></SENT>
<SENT sid="8" pm="."><plain>Read and approved the manuscript: PY XL H-NC C-KK S-KN. </plain></SENT>
</text></p></fn></author-notes><pub-date pub-type="collection"><year>2014</year></pub-date><pub-date pub-type="epub"><day>9</day><month>5</month><year>2014</year></pub-date><volume>9</volume><issue>5</issue><elocation-id>e97079</elocation-id><history><date date-type="received"><day>18</day><month>12</month><year>2013</year></date><date date-type="accepted"><day>14</day><month>4</month><year>2014</year></date></history><permissions><copyright-statement>© 2014 Yang et al</copyright-statement><copyright-year>2014</copyright-year><copyright-holder>Yang et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are properly credited.</license-p></license></permissions><abstract><p><SecTag type="ABS"><text><SENT sid="9" pm="."><plain>An increasing number of genes have been experimentally confirmed in recent years as causative genes to various human diseases. </plain></SENT>
<SENT sid="10" pm="."><plain>The newly available knowledge can be exploited by machine learning methods to discover additional unknown genes that are likely to be associated with diseases. </plain></SENT>
<SENT sid="11" pm="."><plain>In particular, positive unlabeled learning (PU learning) methods, which require only a positive training set P (confirmed disease genes) and an unlabeled set U (the unknown candidate genes) instead of a negative training set N, have been shown to be effective in uncovering new disease genes in the current scenario. </plain></SENT>
<SENT sid="12" pm="."><plain>Using only a single source of data for prediction can be susceptible to bias due to incompleteness and noise in the genomic data and a single machine learning predictor prone to bias caused by inherent limitations of individual methods. </plain></SENT>
<SENT sid="13" pm="."><plain>In this paper, we propose an effective PU learning framework that integrates multiple biological data sources and an ensemble of powerful machine learning classifiers for disease gene identification. </plain></SENT>
<SENT sid="14" pm="."><plain>Our proposed method integrates data from multiple biological sources for training PU learning classifiers. </plain></SENT>
<SENT sid="15" pm="."><plain>A novel ensemble-based PU learning method EPU is then used to integrate multiple PU learning classifiers to achieve accurate and robust disease gene predictions. </plain></SENT>
<SENT sid="16" pm="."><plain>Our evaluation experiments across six disease groups showed that EPU achieved significantly better results compared with various state-of-the-art prediction methods as well as ensemble learning classifiers. </plain></SENT>
<SENT sid="17" pm="."><plain>Through integrating multiple biological data sources for training and the outputs of an ensemble of PU learning classifiers for prediction, we are able to minimize the potential bias and errors in individual data sources and machine learning algorithms to achieve more accurate and robust disease gene predictions. </plain></SENT>
<SENT sid="18" pm="."><plain>In the future, our EPU method provides an effective framework to integrate the additional biological and computational resources for better disease gene predictions. </plain></SENT>
</text></SecTag></p></abstract><funding-group><funding-statement>The authors have no support or funding to report.</funding-statement></funding-group><counts><page-count count="11"/></counts></article-meta></front><body><SecTag type="INTRO"><sec id="s1"><title><text><SENT sid="19" pm="."><plain>Introduction </plain></SENT>
</text></title><p><text><SENT sid="20" pm="."><plain>While high-throughput genomic studies have led to the discovery of hundreds and thousands of candidate disease genes, the identification of genes involved in specific human diseases has remained a fundamental challenge, requiring time-consuming and expensive experimentation. </plain></SENT>
<SENT sid="21" pm="."><plain>Computational approaches that can reliably predict novel disease genes from the vast number of unknown genes will provide a useful alternative to speed up the long and arduous searches for the genetic causes of various human disorders. </plain></SENT>
</text></p><p><text><SENT sid="22" pm="."><plain>Given that an increasing number of genes have been experimentally confirmed over the years as causative genes to various human diseases, it will be useful to develop machine learning methods to identify novel disease genes from the confirmed disease genes as positive training examples, based on the observation that genes associated with similar disease phenotypes are likely to share similar biological characteristics. </plain></SENT>
<SENT sid="23" pm="."><plain>For example, proteins involved in hereditary diseases tend to be long, with more homologs with distant species, but fewer paralogs within human genome [1]. </plain></SENT>
<SENT sid="24" pm="."><plain>They are also likely to attach together to form functional modules such as protein complexes [2]. </plain></SENT>
<SENT sid="25" pm="."><plain>In fact, various studies have shown that genes associated with similar disorders tend to demonstrate similar gene expression profiling [3], high functional similarities [4] [5] and physical interactions between their gene products [6] [7]. </plain></SENT>
</text></p><p><text><SENT sid="26" pm="."><plain>In addition, with disease phenotype similarity data, genes associated with same/similar disease phenotypes are likely to share similar biological functions. </plain></SENT>
<SENT sid="27" pm="."><plain>Given a phonotype phi, we can infer its potential disease genes from those disease genes associated with phenotypes phj (phi and phj are very similar) [8]. </plain></SENT>
</text></p><p><text><SENT sid="28" pm="."><plain>A number of methods above have thus been proposed to prioritize candidate genes based on different kinds of biological data, such as gene sequence data, gene expression profile, evolutionary features, functional annotation data and PPI dataset. </plain></SENT>
<SENT sid="29" pm="."><plain>Adie et al. [9] employed a decision tree algorithm based on a variety of genomic sequence and evolutionary features, such as coding sequence length and evolutionary conservation, presence, and closeness of paralogs in the human genome. </plain></SENT>
<SENT sid="30" pm="."><plain>Topological information on PPI network has also been demonstrated to be useful for disease gene prediction. </plain></SENT>
<SENT sid="31" pm="."><plain>Smalter et al. [10] applied support vector machines (SVM) classifier using PPI topological features in addition to sequence-derived and evolutionary features, while Radivojac et al. [11] built three individual SVM classifiers using three types of features−PPI network, protein sequence and protein functional information−and then built a final classifier to combine the predictions from three individual classifiers for candidate gene prediction. </plain></SENT>
</text></p><p><text><SENT sid="32" pm="."><plain>The research work mentioned above employed classical machine learning methods to build a binary classifier where the confirmed disease genes are used as positive training set P and unknown genes as negative training set N. However, these machine learning techniques hardly perform as well as they could because the negative set N that they used contained unconfirmed disease genes (false negatives). </plain></SENT>
<SENT sid="34" pm="."><plain>In light of aforementioned limitation, recently positive unlabeled learning (PU learning) methods have been proposed for the task by building a classification model in which unknown genes are appropriately treated as an unlabeled set U (instead of a negative set N). </plain></SENT>
<SENT sid="35" pm="."><plain>For example, Mordelet et al. proposed a bagging method ProDiGe for disease gene prediction. </plain></SENT>
<SENT sid="36" pm="."><plain>It iteratively choosed random subsets (RS) from U and then trained multiple classifiers using bias SVM to discriminate P from each subset RS. </plain></SENT>
<SENT sid="37" pm="."><plain>The multiple classifiers were subsequently aggregated to generate the final classifier [12]. </plain></SENT>
<SENT sid="38" pm="."><plain>Given that the RS's were likely to contain less noise (unknown disease genes) than the original set U, it was able to perform better than classical binary classification models that inappropriately used U as negative training data. </plain></SENT>
<SENT sid="39" pm="."><plain>More recently, Yang et al. designed a novel multi-level PU learning algorithm PUDI to build a classifier with better performance for disease gene identification where the unlabeled set U was partitioned into multiple positive and negative sets with confidence scores for building the classifier [13]. </plain></SENT>
</text></p><p><text><SENT sid="40" pm="."><plain>The prior works have clearly shown that integration of various biological data sources is not only desirable but also essential for robust disease gene prediction, since using only a single source of data for prediction is susceptible to incompleteness and noise in the genomic data. </plain></SENT>
<SENT sid="41" pm="."><plain>It is also advantageous to employ an ensemble approach for prediction, since using a single machine learning predictor is similarly in risk of potential bias caused by inherent limitations of individual prediction models. </plain></SENT>
<SENT sid="42" pm="."><plain>In this paper, we propose an effective PU learning framework to integrate multiple biological data sources and an ensemble of powerful machine learning classifiers for disease gene identification. </plain></SENT>
<SENT sid="43" pm="."><plain>In our proposed framework, we first extract multiple positive and negative samples from unlabeled set U through performing random walk with restart on different biological networks. </plain></SENT>
<SENT sid="44" pm="."><plain>We use three biological networks for this paper: protein interaction network, gene expression similarity network, and GO similarity network. </plain></SENT>
<SENT sid="45" pm="."><plain>Then, we build multiple independent PU learning models that utilize the extracted positive and negative samples as training data with different confidence scores. </plain></SENT>
<SENT sid="46" pm="."><plain>Finally, we design a novel ensemble strategy called EPU (Ensemble Positive Unlabeled learning) giving optimized weights to base PU learning models to minimize the overall error rate for accurate disease gene predictions. </plain></SENT>
</text></p><p><text><SENT sid="47" pm="."><plain>We compare EPU with multiple state-of-the-art techniques, namely, multi-level example based learning [14], Smalter's method [10], Xu's method [15] and ProDiGe method [12]. </plain></SENT>
<SENT sid="48" pm="."><plain>The experimental results show that EPU outperforms the existing methods significantly for identifying disease genes on 6 disease groups. </plain></SENT>
<SENT sid="49" pm="."><plain>In addition, our proposed EPU algorithm also achieves better results when it is compared to three base PU learning classifiers, demonstrating that our proposed ensemble-based approach is able to effectively utilize individual classifiers for better performance. </plain></SENT>
<SENT sid="50" pm="."><plain>Finally, we also conduct a case study to show how our proposed EPU algorithm can discover novel disease genes for endocrine and cancer diseases. </plain></SENT>
</text></p></sec></SecTag><SecTag type="METHODS"><sec sec-type="materials|methods" id="s2"><title><text><SENT sid="51" pm="."><plain>Materials and Methods </plain></SENT>
</text></title><p><text><SENT sid="52" pm="."><plain>In this section, we begin with the description of the experimental data used and briefly introduce how the protein interaction network, gene expression similarity network, and GO similarity network [16] [17] [18] are constructed. </plain></SENT>
<SENT sid="53" pm="."><plain>Then we will present the schema of our proposed EPU algorithm. </plain></SENT>
</text></p><sec id="s2a"><title><text><SENT sid="54" pm="."><plain>Experimental data and gene network modeling </plain></SENT>
</text></title><p><text><SENT sid="55" pm="."><plain>In this paper, we have exploited the following biological data human protein interaction data, gene expression data, gene ontology, and phenotype-gene association data. </plain></SENT>
</text></p><p><text><SENT sid="56" pm="."><plain>Human protein interaction data (PPI) is downloaded from the Human Protein Reference Database (HPRD) [19] and Online Predicted Human Interaction Database (OPHID) [20]. </plain></SENT>
<SENT sid="57" pm="."><plain>The combined PPI dataset contains 143,939 PPIs among a total of 13,035 human proteins. </plain></SENT>
<SENT sid="58" pm="."><plain>We build a protein interaction network GPPI = (VPPI, EPPI) where VPPI represents the set of vertices (proteins) and EPPI denotes all edges (detected pairwise interactions between proteins). GPPI can be represented as its matrix format, i.e. WPPI = [wij] where wij = 1 if the corresponding protein pair ; 0 otherwise. </plain></SENT>
</text></p><p><text><SENT sid="59" pm="."><plain>Gene expression data is obtained from RNASeq data which is made publicly available in the EBI ArrayExpress, by the Illumina Human BodyMap 2.0 (<ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE30611">http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE30611</ext-link>). </plain></SENT>
<SENT sid="60" pm="."><plain>The dataset comprises Fastq reads from the paired-end sequencing of cells from 16 human tissue types, including colon, heart, kidney, white blood cells and so on, using the Illumina HiSeq next generation sequencing platform. </plain></SENT>
<SENT sid="61" pm="."><plain>This dataset represents the expression values of 17,652 human genes on 16 human tissue types. </plain></SENT>
<SENT sid="62" pm="."><plain>Suppose gene gi and gj are represented as their gene expression profile vectors (xi 1, xi 2,…, xin) and (xj 1, xj 2,…, xjn) respectively where xik (k = 1, 2, …, n) denotes the expression value of gene i in the k-th tissue. </plain></SENT>
<SENT sid="63" pm="."><plain>Pearson correlation coefficient is employed to measure the similarity between gi and gj:(1)where . </plain></SENT>
</text></p><p><text><SENT sid="64" pm="."><plain>We build a gene expression similarity network GGE = (VGE, EGE), where  represents a set of genes occurring in the gene expression data and EGE represents a set of edges between the genes in VGE. </plain></SENT>
<SENT sid="65" pm="."><plain>For each gene gi, we ranked all genes gj in VGE where i≠j according to decreasing order of simGE(gi, gj), and add an edge (gi, gj) to EGE if gj is in the top 5 of the list. </plain></SENT>
<SENT sid="66" pm="."><plain>This helps to filter low similarity pairs and potential noise in gene expression data. </plain></SENT>
<SENT sid="67" pm="."><plain>Then we transform the gene expression network GGE to its matrix format where the edges of two genes are reformatted to their gene expression similarity in equation (1). </plain></SENT>
</text></p><p><text><SENT sid="68" pm="."><plain>Gene Ontology (GO, <ext-link ext-link-type="uri" xlink:href="http://www.geneontology.org/">http://www.geneontology.org/</ext-link>) is a set of controlled vocabulary used to annotate genes and gene products [21]. </plain></SENT>
<SENT sid="69" pm="."><plain>Gene Ontology provides three sub-ontologies, namely, biological process (BP), molecular function (MF) and cellular components (CC) [21]. </plain></SENT>
<SENT sid="70" pm="."><plain>For each gene, we build a feature vector using its annotations from three sub-onotolgies, i.e. {MF1,…,MF|SMF|, BP1,…,BP|SBP|, CC1,…,CC|SCC|}. </plain></SENT>
<SENT sid="71" pm="."><plain>For example, a gene gi is represented as gene vector gi = (mfi1, …, mfi|SMF|, bpi1, …, bpi|SBP|, cci1, …, cci|SCC|), where mfij (similar for bpij, ccij) is GO term similarity between gi and the feature MFj. </plain></SENT>
<SENT sid="72" pm="."><plain>Since the GO terms of BP, MF and CC are organized into DAG structure, we use the computational method in [22] to measure the similarity of two GO terms. </plain></SENT>
<SENT sid="73" pm="."><plain>And |SMF| is number of selected MF term features. </plain></SENT>
<SENT sid="74" pm="."><plain>We choose the GO features that could help distinguish disease genes from non-disease genes with strategy in [13] and top 1000 scored features were selected for each of three feature groups, i.e. BP, MF and CC, respectively. </plain></SENT>
<SENT sid="75" pm="."><plain>We then build GO similarity network GGO = (VGO, EGO), where VGO is the gene set annotated in GO dataset and EGO is a set of edges between the genes in VGO. </plain></SENT>
<SENT sid="76" pm="."><plain>Similarly to the gene expression similarity network, we keep those top 5 edges which have highest similarities to each gene and other edges. GGO can be represented as its matrix format, i.e. WGO = [wij]. </plain></SENT>
<SENT sid="77" pm="."><plain>Given a gene gi, if gj is one of top 5 lists of gi, wij is normalized as:(2)otherwise, wij = 0, where Dis(gi, gj) denotes Euclidean distance between gi and gj and 0≤wij≤1. </plain></SENT>
</text></p><sec id="s2a1"><title><text><SENT sid="78" pm="."><plain>Phenotype-gene association data </plain></SENT>
</text></title><p><text><SENT sid="79" pm="."><plain>4260 phenotype-gene association data, spanning 2659 known disease genes and 3200 disease phenotypes, are obtained from the latest version of OMIM (<ext-link ext-link-type="uri" xlink:href="http://omim.org/">http://omim.org/</ext-link>) [23]. </plain></SENT>
<SENT sid="80" pm="."><plain>Goh et al. [6] have categorized the 3200 disease phenotypes in OMIM database into 22 disease groups/classes, i.e. Cancer, Metabolic, Neurological, Endocrine, etc, based on the physiological system affected. </plain></SENT>
<SENT sid="81" pm="."><plain>For example, the Endocrine disease group comprises 62 OMIM phenotypes, including OMIM 241850 (Bamforth-Lazarus syndrome) and OMIM 304800 (Diabetes insipidus, nephrogenic) etc. </plain></SENT>
</text></p></sec><sec id="s2a2"><title><text><SENT sid="82" pm="."><plain>Phenotype similarity network </plain></SENT>
</text></title><p><text><SENT sid="83" pm="."><plain>Disease phenotype similarity network [24], is defined as GPH = (VPH, EPH), where VPH denotes the set of disease phenotypes and EPH denotes relevant phenotype pairs. </plain></SENT>
<SENT sid="84" pm="."><plain>Disease phenotypes in VPH are represented as feature vectors in which feature terms are Medical Subject Headings (MeSH) controlled vocabulary, and phenotype similarities in EPH are evaluated underline concept relevance and frequency of MeSH terms appearing in text description of OMIM documents. </plain></SENT>
<SENT sid="85" pm="."><plain>According to Vanunu et al. [8], phenotype pairs with high similarities are regarded as informative and reliable. </plain></SENT>
<SENT sid="86" pm="."><plain>Therefore, we apply logistic function to filter out low phenotypic similarities in EPH, following [2] [8]. </plain></SENT>
</text></p></sec></sec><sec id="s2b"><title><text><SENT sid="87" pm="."><plain>The proposed technique EPU </plain></SENT>
</text></title><p><text><SENT sid="88" pm="."><plain>The schema of our EPU algorithm is presented in Figure 1. </plain></SENT>
<SENT sid="89" pm="."><plain>EPU first selects candidate positives from positive genes and reliable negatives from unlabeled genes. </plain></SENT>
<SENT sid="90" pm="."><plain>It then builds three gene similarity networks using PPI data, gene expression data and Gene Ontology data and applies random walk on the three networks to propagate weights to unlabeled genes that reflect likelihoods of belonging to positive/negative class. </plain></SENT>
<SENT sid="91" pm="."><plain>We then exploit the weighted genes to build three diverse classification models to predict “soft” labels for test genes. </plain></SENT>
<SENT sid="92" pm="."><plain>Finally, an ensemble learning algorithm combines the prediction results from the classifiers to make a final prediction for the classification of the unknown test gene. </plain></SENT>
</text></p><SecTag type="FIG"><fig id="pone-0097079-g001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0097079.g001</object-id><label>Figure 1</label><caption><title><text><SENT sid="93" pm="."><plain>Overall schema of EPU learning algorithm. </plain></SENT>
</text></title><p><text><SENT sid="94" pm="."><plain>EPU is a framework that utilizes positive and ‘weighted’ unlabeled examples to build an ensemble classifier for disease gene identification. </plain></SENT>
<SENT sid="95" pm="."><plain>First of all, EPU extracts candidate positives (CP) and reliable negatives (RN) from unlabeled set. </plain></SENT>
<SENT sid="96" pm="."><plain>Then it applies random walk algorithm to weight remaining unlabeled genes on genetic networks. </plain></SENT>
<SENT sid="97" pm="."><plain>To achieve reliable and robust measure on U, EPU consults three biological networks, PPI network, GO similarity network and Gene expression network. </plain></SENT>
<SENT sid="98" pm="."><plain>After obtained ensemble weighted genes, EPU builds three PU learning classifiers. </plain></SENT>
<SENT sid="99" pm="."><plain>Finally, a novel ensemble strategy is applied to combines the outputs from these classifiers to make final predictions. </plain></SENT>
</text></p></caption><graphic xlink:href="pone.0097079.g001"/></fig></SecTag><p><text><SENT sid="100" pm="."><plain>Suppose all disease genes from OMIM are stored into a disease gene set DIS. </plain></SENT>
<SENT sid="101" pm="."><plain>All the other genes that are not a member of DIS will be treated as unknown/unlabeled genes and be stored into a set UG (contains 16,570 genes) [25]. </plain></SENT>
<SENT sid="102" pm="."><plain>Each gene in DIS and UG is represented as a feature vector, namely,  where m is the total number of features from GO terms, protein domains and PPI topological features, following our previous work [13]. </plain></SENT>
</text></p><p><text><SENT sid="103" pm="."><plain>In the next section, we describe how to predict novel disease genes given the confirmed disease genes for a particular disease or disorder. </plain></SENT>
<SENT sid="104" pm="."><plain>The confirmed disease genes for the given disorder group are treated as positive set P (P  DIS) while randomly selected unknown genes from UG are treated as unlabeled set U (U  UG, |U| = |P|), following the settings in [9] [10] [15]. </plain></SENT>
</text></p></sec><sec id="s2c"><title><text><SENT sid="105" pm="."><plain>Weighting unlabeled genes by integrating multiple biological evidences </plain></SENT>
</text></title><p><text><SENT sid="106" pm="."><plain>Given a particular disease class and its known associated disease genes, we first build the training data sets for machine learning by prioritizing the candidate positives and reliable negatives based on their similarity to the query disease class. </plain></SENT>
<SENT sid="107" pm="."><plain>We build three gene similarity networks using PPI, gene expression and GO as described above, and perform a random walk with restart algorithm on these three gene similarity networks to estimate the likelihood of the unlabeled genes belonging to disease class or non-disease class. </plain></SENT>
<SENT sid="108" pm="."><plain>The details are as follows. </plain></SENT>
</text></p><sec id="s2c1"><title><text><SENT sid="109" pm="."><plain>Extracting candidate positives and reliable negatives </plain></SENT>
</text></title><p><text><SENT sid="110" pm="."><plain>As a typical positive set P is relatively small, we want to find a set of candidate positive genes CP to complement P. Given that recent studies have shown that similar phenotypes are often caused by functionally related disease genes [4] [6], we could populate the set of candidate positive genes CP with genes associated to similar/relevant phenotypes, based on the principle of guilt-by-association. </plain></SENT>
<SENT sid="112" pm="."><plain>In other words, given a query disease group/class, we can use its associated phenotypes to uncover similar disease phenotypes, as shown in Figure S1. </plain></SENT>
</text></p><p><text><SENT sid="113" pm="."><plain>Having identified the candidate positive genes CP, let us now describe how to extract reliable negative gene set RN. </plain></SENT>
<SENT sid="114" pm="."><plain>We consider reliable negatives as those unlabeled genes that are very different from positive set P. To identify such genes, we first build a “positive representative vector” (pr) by summing up gene vectors in P and normalizing it. </plain></SENT>
<SENT sid="116" pm="."><plain>Then, we compute the average Euclidean distance [26] of every unlabeled gene gi in U from pr. </plain></SENT>
<SENT sid="117" pm="."><plain>To extract the reliable negative genes for RN, we regard an unlabeled gene gi as a member of RN if its distance from pr is longer than the average distance (of all the genes in U) from pr, formalized as follows:(3)where  is the Euclidean distance between gene gi and positive representative vector pr. </plain></SENT>
<SENT sid="118" pm="."><plain>We compute an average distance  of all the unlabeled gene in U from pr as:  </plain></SENT>
</text></p></sec><sec id="s2c2"><title><text><SENT sid="119" pm="."><plain>Ensemble weighted unlabeled genes via performing label propagation on multiple networks </plain></SENT>
</text></title><p><text><SENT sid="120" pm="."><plain>We now have the given positive set P, a candidate positive set CP, a reliable negative set RN and a remaining unlabeled set  for machine learning. </plain></SENT>
<SENT sid="121" pm="."><plain>To build a robust classification model, we will extract those genes with reliable labels that are near the decision boundary between the positive and negative classes. </plain></SENT>
<SENT sid="122" pm="."><plain>We adapt the Random Walk with Restart algorithm [27] to perform flow propagation which spreads the label information from P, CP and RN to the unlabeled genes in  on the biological networks that we have constructed, namely the PPI network GPPI, the GO similarity network GGO and the gene expression similarity network GGE as described earlier. </plain></SENT>
</text></p><p><text><SENT sid="123" pm="."><plain>Formally, let R0 be an initialization vector where primitive scores are assigned to all genes in three networks to indicate the genes' potential classification labels. </plain></SENT>
<SENT sid="124" pm="."><plain>Let p0,  and n0 denote the initial values for genes in P, CP and RN respectively, as follows. </plain></SENT>
<SENT sid="125" pm="."><plain>The genes  are all given a score p0(gi) = +1, indicating their disease gene status. </plain></SENT>
<SENT sid="126" pm="."><plain>Each candidate positive gene  is assigned a score that computes its maximal phenotypic similarity to the known disease genes in P,, where  denotes disease phenotypes caused by gene gi, and PH(P) denotes disease phenotypes caused by disease set P. For genes in reliable negative set RN, to balance total amount of flows between positive genes and negative genes, the initial score for negative gene gi is assigned with(4)where  is a total amount of positive gene set. </plain></SENT>
<SENT sid="128" pm="."><plain>The remaining unlabeled genes in  are assigned an initial score of 0. </plain></SENT>
</text></p><p><text><SENT sid="129" pm="."><plain>For each of the three biological networks GPPI, GGE and GGO, prior influence from the seed nodes in P, CP and RN are propagated to their direct neighbors, and then continue to spread to other adjacent nodes iteratively across the network. </plain></SENT>
<SENT sid="130" pm="."><plain>Given R0 the initial score vector (step 0), Rt, the score vector at step t, can be calculated as follows:(5)where R1 = R0 and W = D−1W is a normalized format of matrix W, . </plain></SENT>
<SENT sid="131" pm="."><plain>Here D is the diagonal matrix and . α represents the percentage of flow back to original seed nodes in P, CP and RN during each iteration. </plain></SENT>
<SENT sid="132" pm="."><plain>The default value of 0.7 is used for α, following [16]. </plain></SENT>
</text></p><p><text><SENT sid="133" pm="."><plain>Eventually, the information flow will converge to a steady state [27]. </plain></SENT>
<SENT sid="134" pm="."><plain>In our case, the Random Walk with Restart algorithm will stop its iterative process when the difference between two steps Rt and Rt-1 is less than 10−6 [16], measured by L1 norm. </plain></SENT>
<SENT sid="135" pm="."><plain>The scores for unlabeled genes from the three gene networks are combined into one integrated score:(6)where Rt(g,WPPI), Rt(g,WGO) and Rt(g,WGE) are the scores for gene g in the PPI, GO similarity and gene expression similarity networks respectively. </plain></SENT>
</text></p></sec></sec><sec id="s2d"><title><text><SENT sid="136" pm="."><plain>Ensemble positive unlabeled learning EPU </plain></SENT>
</text></title><p><text><SENT sid="137" pm="."><plain>Next, we describe how to build three separate PU learning classification models Support Vector Machine SVM, K-Nearest Neighbor, and Naïve Bayes classifier−to classify genes into two classes C = {+, −}, where ‘+’ denotes positive/disease class and ‘−’ presents negative/non-disease class. </plain></SENT>
</text></p><sec id="s2d1"><title><text><SENT sid="138" pm="."><plain>PU learning model 1: Weighted K-Nearest Neighbor (WKNN) </plain></SENT>
</text></title><p><text><SENT sid="139" pm="."><plain>KNN is an instance based learning method, which classifies an unknown test gene based on the class labels of its top K nearest training example genes, i.e. based on the majority class vote of its nearest K neighbors. </plain></SENT>
<SENT sid="140" pm="."><plain>The distance between the test gene and other training examples can be computed using common distance metrics such as Euclidean distance. </plain></SENT>
<SENT sid="141" pm="."><plain>Given a test gene gi and its k nearest neighbor set Di, we divide Di into positive and negative training subsets, namely Di+ = {g|Int_score(g)≥0, g∈Di} and Di- = {g|Int_score(g)&lt;0, g∈Di} based on these neighbors' integrated scores. </plain></SENT>
<SENT sid="142" pm="."><plain>The conditional probability of the test gene gi with respect to disease (+)/non-disease class (−), is measured as(7) </plain></SENT>
</text></p><p><text><SENT sid="143" pm="."><plain>Note that weighted KNN accumulates both positive and negative integrated scores in Di and estimates the probability of gi belonging to positive (or negative) class based on the accumulated scores in that class. </plain></SENT>
</text></p></sec><sec id="s2d2"><title><text><SENT sid="144" pm="."><plain>PU learning model 2: Weighted Naïve Bayes (WNB) </plain></SENT>
</text></title><p><text><SENT sid="145" pm="."><plain>Given a test gene gi, the probability that gene gi belongs to a class cj () can be computed using Bayes' theorem as:(8)where the probability  is a constant for the positive and negative classes. </plain></SENT>
<SENT sid="146" pm="."><plain>Here, we define the prior probabilities of the positive and negative classes as 0.5, i.e. P(Y = +) = P(Y = −) = 0.5. </plain></SENT>
<SENT sid="147" pm="."><plain>Given a gene vector , the conditional probability of feature fk associated with class cj, denoted as P(fk|Y = cj), is calculated as:(9)where g(fk) is the value of feature fk in gene vector , is defined as either  or , depending on cj is positive class (+) or negative class (−). </plain></SENT>
</text></p><p><text><SENT sid="148" pm="."><plain>By assuming that the probabilities of features are independent given the class Y = cj, we obtain the Naïve Bayes classifier:(10) </plain></SENT>
</text></p></sec><sec id="s2d3"><title><text><SENT sid="149" pm="."><plain>PU learning model 3: Multi-level Support Vector Machine (MSVM) </plain></SENT>
</text></title><p><text><SENT sid="150" pm="."><plain>Based on the integrated score Int_score(g), we further partition the unlabeled genes  into three parts: likely positive set LP (genes get higher positive integrated scores), likely negative set LN (genes get lower negative integrated scores) and weak negative set WN (remaining genes) using the following criteria:(11) </plain></SENT>
</text></p><p><text><SENT sid="151" pm="."><plain>We then build a multi-level classifier based on positive training set P, reliable negative set RN, and three newly generated sets LP, LN, and WN, via weighted support vector machine technique [28] [29], to take into account of the inherently different levels of trustworthiness of labels in the five gene set. </plain></SENT>
</text></p><p><text><SENT sid="152" pm="."><plain>The objective function of Weighted SVM can be defined as [14]:(12) </plain></SENT>
</text></p><p><text><SENT sid="153" pm="."><plain>Subject to:  where the values of parameters , , ,  and  can be decided by using cross-validation techniques. </plain></SENT>
<SENT sid="154" pm="."><plain>Finally, we apply our MSVM model  to compute the probability of test gene gi belonging to class cj () for its classification. </plain></SENT>
</text></p><p><text><SENT sid="155" pm="."><plain>Note that while the candidate positive set CP plays a role in assigning the genes in U - RN to one of the 3 subsets LP, LN and WN, it does not overlap with the training set  and hence is not used in the construction of the MSVM model. </plain></SENT>
</text></p></sec><sec id="s2d4"><title><text><SENT sid="156" pm="."><plain>Ensemble-based algorithm for integration of individual classifiers </plain></SENT>
</text></title><p><text><SENT sid="157" pm="."><plain>In order to perform more robust classification, we design a novel ensemble learning model to integrate the three classification models constructed above. </plain></SENT>
</text></p><p><text><SENT sid="158" pm="."><plain>Suppose  denotes the probability of gene  belonging to class c as predicted by the jth classifier. </plain></SENT>
<SENT sid="159" pm="."><plain>We can organize the genes in D in the following matrix:(13)where k is the number of individual classifiers (here, k = 3), and |D| is the size of training set D. </plain></SENT>
</text></p><p><text><SENT sid="160" pm="."><plain>Our ensemble model  integrates the outputs from the multiple classification models as follows:(14)where  is a weight vector that indicates the importance of individual models. </plain></SENT>
<SENT sid="161" pm="."><plain>The final output value “1” denotes disease/positive class and ‘−1’ denotes non-disease/negative class. </plain></SENT>
</text></p><p><text><SENT sid="162" pm="."><plain>The classifier weight  can be learned from training set D as follows. </plain></SENT>
<SENT sid="163" pm="."><plain>We define  as training error of the hypothesis of our ensemble model:(15)where yi (yi {−1,1}) and oi (oi {−1,1}) are the actual class and predicted class by our ensemble model for training gene  respectively.  is a linear square error function that evaluates the difference between yi and oi. </plain></SENT>
<SENT sid="164" pm="."><plain>We minimize  to guarantee the classification output o with minimal error rate and calculate the weight vector . </plain></SENT>
</text></p><p><text><SENT sid="165" pm="."><plain>Here, gradient decent is applied to search the probable weight vectors in error surface. </plain></SENT>
<SENT sid="166" pm="."><plain>The gradient of E for , denoted as , is the derivative of E with respect to each component of the vector. </plain></SENT>
<SENT sid="167" pm="."><plain>From above equation, we obtain each component of  as follows:(16) </plain></SENT>
</text></p><p><text><SENT sid="168" pm="."><plain>The following training rule guarantees that  is adjusted in the direction of steepest descent along the error surface: , where . η is a small positive constant, called learning rate, to determine the step size in gradient decent exploration. </plain></SENT>
<SENT sid="169" pm="."><plain>We set η = 0.001, following previous work [30]. </plain></SENT>
<SENT sid="170" pm="."><plain>The negative gradient  gives the direction of steepest decrease. </plain></SENT>
<SENT sid="171" pm="."><plain>According to equations above, we update the gradient descent rule as follows:(17) </plain></SENT>
</text></p><p><text><SENT sid="172" pm="."><plain>The overall ensemble learning method is summarized in Figure 2. </plain></SENT>
<SENT sid="173" pm="."><plain>First, we assign an initial random weight vector for . </plain></SENT>
<SENT sid="174" pm="."><plain>The ensemble model is then applied to all training genes and each weight is then updated by adding  computed according to equation (17) above. </plain></SENT>
<SENT sid="175" pm="."><plain>This process is repeated until  converges. </plain></SENT>
<SENT sid="176" pm="."><plain>Note that if η is a large number, the search exploration might overstep the minimum point in the error surface rather than settling into it. </plain></SENT>
<SENT sid="177" pm="."><plain>Therefore, the value of η should be gradually reduced as the number of iteration grows. </plain></SENT>
</text></p><SecTag type="FIG"><fig id="pone-0097079-g002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0097079.g002</object-id><label>Figure 2</label><caption><title><text><SENT sid="178" pm="."><plain>Ensemble learning algorithm. </plain></SENT>
</text></title></caption><graphic xlink:href="pone.0097079.g002"/></fig></SecTag></sec></sec></sec></SecTag><SecTag type="RESULTS"><sec id="s3"><title><text><SENT sid="179" pm="."><plain>Experimental Results </plain></SENT>
</text></title><p><text><SENT sid="180" pm="."><plain>For evaluation, we benchmark our proposed EPU algorithm against four state-of-the-art techniques for disease gene prediction: PUDI method, Smalter's method, Xu's method and ProDiGe. </plain></SENT>
<SENT sid="181" pm="."><plain>In addition, we also compare the performance of EPU with its base learning models, namely MSVM, WKNN and WNB. </plain></SENT>
<SENT sid="182" pm="."><plain>Finally, we demonstrate novel disease gene prediction using the EPU algorithm. </plain></SENT>
</text></p><sec id="s3a"><title><text><SENT sid="183" pm="."><plain>Experimental settings </plain></SENT>
</text></title><p><text><SENT sid="184" pm="."><plain>We use the disease classes with at least 50 confirmed disease genes from the 21 specific disease classes in [6] for evaluating our classification algorithm. </plain></SENT>
<SENT sid="185" pm="."><plain>There are six such disease classes: cardiovascular disease, endocrine disease, cancer disease, metabolic disease, neurological disease, and ophthalmological disease (See Table S1 for the exact numbers of disease genes for each class). </plain></SENT>
<SENT sid="186" pm="."><plain>Given a particular disease class, the positive set P consists of all its confirmed disease genes, while the unlabeled set U is formed by randomly selecting from the genes that are not known to be associated with any disease such that |P| = |U|, following the setting in [9] [10] [15]. </plain></SENT>
<SENT sid="187" pm="."><plain>To avoid bias in sampling, we randomly select 10 groups of unlabeled set U. All experimental evaluations of the classification models are done on identical groups of training and test data, and we report the average performance over the 10 groups of (P+U) sets. </plain></SENT>
<SENT sid="189" pm="."><plain>To evaluate the performance of our algorithm, 3 fold cross validation is applied where two folds in P+U as the training set build classifier while remaining one fold is the test set. </plain></SENT>
<SENT sid="190" pm="."><plain>Next, positive training genes in P are used as seed nodes on multiple genetic networks to weight unlabeled training genes in U via flow propagation. </plain></SENT>
<SENT sid="191" pm="."><plain>Then, to obtain the ‘soft’ classes of training genes from component learning models, leave-one-out cross-validation (LOOCV) is used on 2 fold training samples, from which each training sample is singled out to evaluate its ‘soft’ classes by component classifiers (MSVM, WKNN and WNB), which are built on the other training samples. </plain></SENT>
<SENT sid="192" pm="."><plain>After LOOCV, these training samples with the ‘soft’ classes are as input data to build an ensemble learning model (as shown in Figure 2) to predict 1 fold test fold. </plain></SENT>
<SENT sid="193" pm="."><plain>The average results on 3×10 groups of (P+U) sets are reported on experimental part. </plain></SENT>
</text></p></sec><sec id="s3b"><title><text><SENT sid="194" pm="."><plain>Evaluation metrics </plain></SENT>
</text></title><p><text><SENT sid="195" pm="."><plain>We use precision, recall, and F-measure to measure the performance of our classification models on each of the six disease classes. </plain></SENT>
<SENT sid="196" pm="."><plain>The F-measure is the harmonic mean of precision (denoted as p) and recall (denoted as r), defined as(18) </plain></SENT>
</text></p><p><text><SENT sid="197" pm="."><plain>The value of F-measure is large only when both of p and r are high, and small when either of them is poor. </plain></SENT>
<SENT sid="198" pm="."><plain>This is appropriate for our objective of accurately predicting disease genes, as deficiencies in either precision or recall will be reflected by a low F-measure. </plain></SENT>
</text></p></sec><sec id="s3c"><title><text><SENT sid="199" pm="."><plain>Experimental Results </plain></SENT>
</text></title><sec id="s3c1"><title><text><SENT sid="200" pm="."><plain>Benchmarking of EPU ensemble learning algorithm against state-of-art techniques </plain></SENT>
</text></title><p><text><SENT sid="201" pm="."><plain>First, we compared our EPU algorithm against four state-of-the-art techniques, namely, PUDI method [13], Smalter's method [10], Xu's method [15] and ProDiGe [12]. Table 1 shows that our proposed EPU, on average, is 6.5%, 15.1%, 16.2% and 16.4% better than PUDI, ProDiGe, Smalter's method, Xu's method in terms of F-measure respectively. </plain></SENT>
<SENT sid="202" pm="."><plain>In particular, EPU can achieve much better precision and consistently better recall when compared against the recently proposed method PUDI. </plain></SENT>
<SENT sid="203" pm="."><plain>It shows that EPU can effectively extract hidden positive and negative data from the unlabeled data to boost classification performance. </plain></SENT>
</text></p><SecTag type="TABLE"><table-wrap id="pone-0097079-t001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0097079.t001</object-id><label>Table 1</label><caption><title><text><SENT sid="204" pm="."><plain>Overall comparison of classification performance among different techniques. </plain></SENT>
</text></title></caption><alternatives><graphic id="pone-0097079-t001-1" xlink:href="pone.0097079.t001"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup><thead><tr><td align="left" rowspan="1" colspan="1"><text><SENT sid="205" pm="."><plain>Disease group </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="206" pm="."><plain>Techniques </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="207" pm="."><plain>Precision (p) </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="208" pm="."><plain>Recall (r) </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="209" pm="."><plain>F-measure (F) </plain></SENT>
</text></td></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1"><text><SENT sid="210" pm="."><plain>Cardiovascular </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="211" pm="."><plain>PUDI </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="212" pm="."><plain>82.0% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="213" pm="."><plain>80.3% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="214" pm="."><plain>80.4% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="215" pm="."><plain>ProDiGe </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="216" pm="."><plain>54.3% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="217" pm="."><plain>96.3% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="218" pm="."><plain>69.3% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="219" pm="."><plain>Smalter's method </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="220" pm="."><plain>75.4% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="221" pm="."><plain>67.6% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="222" pm="."><plain>70.6% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="223" pm="."><plain>Xu's method </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="224" pm="."><plain>72.1% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="225" pm="."><plain>60.0% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="226" pm="."><plain>65.4% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="227" pm="."><plain>EPU </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="228" pm="."><plain>85.2% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="229" pm="."><plain>81.0% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="230" pm="."><plain>84.1% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"><text><SENT sid="231" pm="."><plain>Endocrine </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="232" pm="."><plain>PUDI </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="233" pm="."><plain>83.6% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="234" pm="."><plain>75.3% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="235" pm="."><plain>79.2% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="236" pm="."><plain>ProDiGe </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="237" pm="."><plain>57.3% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="238" pm="."><plain>87.7% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="239" pm="."><plain>69.3% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="240" pm="."><plain>Smalter's method </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="241" pm="."><plain>76.4% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="242" pm="."><plain>58.8% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="243" pm="."><plain>66.5% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="244" pm="."><plain>Xu's method </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="245" pm="."><plain>75.4% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="246" pm="."><plain>62.0% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="247" pm="."><plain>68.0% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="248" pm="."><plain>EPU </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="249" pm="."><plain>88.1% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="250" pm="."><plain>87.7% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="251" pm="."><plain>87.9% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"><text><SENT sid="252" pm="."><plain>Neurological </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="253" pm="."><plain>PUDI </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="254" pm="."><plain>70.3% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="255" pm="."><plain>80.1% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="256" pm="."><plain>74.9% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="257" pm="."><plain>ProDiGe </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="258" pm="."><plain>63.1% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="259" pm="."><plain>74.0% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="260" pm="."><plain>68.1% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="261" pm="."><plain>Smalter's method </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="262" pm="."><plain>60.6% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="263" pm="."><plain>65.9% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="264" pm="."><plain>63.1% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="265" pm="."><plain>Xu's method </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="266" pm="."><plain>59.7% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="267" pm="."><plain>66.7% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="268" pm="."><plain>63.0% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="269" pm="."><plain>EPU </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="270" pm="."><plain>78.2% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="271" pm="."><plain>80.4% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="272" pm="."><plain>78.6% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"><text><SENT sid="273" pm="."><plain>Metabolic </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="274" pm="."><plain>PUDI </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="275" pm="."><plain>80.1% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="276" pm="."><plain>84.8% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="277" pm="."><plain>82.4% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="278" pm="."><plain>ProDiGe </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="279" pm="."><plain>58.7% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="280" pm="."><plain>84.5% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="281" pm="."><plain>69.3% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="282" pm="."><plain>Smalter's method </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="283" pm="."><plain>59.1% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="284" pm="."><plain>84.7% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="285" pm="."><plain>69.6% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="286" pm="."><plain>Xu's method </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="287" pm="."><plain>65.6% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="288" pm="."><plain>78.3% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="289" pm="."><plain>71.4% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="290" pm="."><plain>EPU </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="291" pm="."><plain>83.3% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="292" pm="."><plain>93.9% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="293" pm="."><plain>90.9% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"><text><SENT sid="294" pm="."><plain>Ophthalmological </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="295" pm="."><plain>PUDI </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="296" pm="."><plain>71.6% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="297" pm="."><plain>78.5% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="298" pm="."><plain>74.9% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="299" pm="."><plain>ProDiGe </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="300" pm="."><plain>58.3% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="301" pm="."><plain>77.7% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="302" pm="."><plain>66.6% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="303" pm="."><plain>Smalter's method </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="304" pm="."><plain>56.7% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="305" pm="."><plain>77.8% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="306" pm="."><plain>65.5% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="307" pm="."><plain>Xu's method </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="308" pm="."><plain>64.2% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="309" pm="."><plain>71.3% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="310" pm="."><plain>67.4% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="311" pm="."><plain>EPU </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="312" pm="."><plain>89.3% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="313" pm="."><plain>81.0% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="314" pm="."><plain>84.7% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"><text><SENT sid="315" pm="."><plain>Cancer </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="316" pm="."><plain>PUDI </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="317" pm="."><plain>76.3% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="318" pm="."><plain>80.0% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="319" pm="."><plain>78.0% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="320" pm="."><plain>ProDiGe </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="321" pm="."><plain>71.1% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="322" pm="."><plain>79.8% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="323" pm="."><plain>75.3% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="324" pm="."><plain>Smalter's method </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="325" pm="."><plain>73.8% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="326" pm="."><plain>79.0% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="327" pm="."><plain>76.3% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="328" pm="."><plain>Xu's method </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="329" pm="."><plain>71.0% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="330" pm="."><plain>79.7% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="331" pm="."><plain>75.1% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="332" pm="."><plain>EPU </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="333" pm="."><plain>81.2% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="334" pm="."><plain>84.5% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="335" pm="."><plain>82.6% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"><text><SENT sid="336" pm="."><plain>Average performance </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="337" pm="."><plain>PUDI </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="338" pm="."><plain>77.3% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="339" pm="."><plain>79.8% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="340" pm="."><plain>78.3% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="341" pm="."><plain>ProDiGe </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="342" pm="."><plain>60.5% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="343" pm="."><plain>83.3% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="344" pm="."><plain>69.7% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="345" pm="."><plain>Smalter's method </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="346" pm="."><plain>67.0% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="347" pm="."><plain>72.3% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="348" pm="."><plain>68.6% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="349" pm="."><plain>Xu's method </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="350" pm="."><plain>68.0% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="351" pm="."><plain>69.7% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="352" pm="."><plain>68.4% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="353" pm="."><plain>EPU </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="354" pm="."><plain>84.2% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="355" pm="."><plain>84.8% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="356" pm="."><plain>84.8% </plain></SENT>
</text></td></tr></tbody></table></alternatives><table-wrap-foot><fn id="nt101"><label/><p><text><SENT sid="357" pm="."><plain>PUDI is a SVM-based approach that partitions unlabeled genes into multiple levels with different associations to confirmed disease genes. </plain></SENT>
<SENT sid="358" pm="."><plain>ProDiGe is a bagging method that iteratively chooses random subsets from unlabeled subset and trains multiple classifiers. </plain></SENT>
<SENT sid="359" pm="."><plain>Smalter's method integrates multiple biological features, such as topological features, sequence-derived features, evolutionary age features. </plain></SENT>
<SENT sid="360" pm="."><plain>Xu's method employs the KNN classifier to predict disease genes. </plain></SENT>
</text></p></fn></table-wrap-foot></table-wrap></SecTag></sec><sec id="s3c2"><title><text><SENT sid="361" pm="."><plain>Comparison of EPU with base classifiers </plain></SENT>
</text></title><p><text><SENT sid="362" pm="."><plain>Next, we compared the performance of our proposed EPU against its base classifiers MSVM, WNB, WKNN. </plain></SENT>
<SENT sid="363" pm="."><plain>As shown in Table 2, on average, MSVM achieved the highest F-measure (81.3%), much higher than WNB (69.5%) and WKNN (68.7%). </plain></SENT>
<SENT sid="364" pm="."><plain>This is not surprising as MSVM can handle multiple weighted positive and negative sets when building its classification model. </plain></SENT>
<SENT sid="365" pm="."><plain>Furthermore, SVM is known to perform significantly better than NB and KNN in many real-world applications. </plain></SENT>
</text></p><SecTag type="TABLE"><table-wrap id="pone-0097079-t002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0097079.t002</object-id><label>Table 2</label><caption><title><text><SENT sid="366" pm="."><plain>Overall comparison to single-expert classifiers. </plain></SENT>
</text></title></caption><alternatives><graphic id="pone-0097079-t002-2" xlink:href="pone.0097079.t002"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup><thead><tr><td align="left" rowspan="1" colspan="1"><text><SENT sid="367" pm="."><plain>Disease group </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="368" pm="."><plain>Techniques </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="369" pm="."><plain>Precision (p) </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="370" pm="."><plain>Recall (r) </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="371" pm="."><plain>F-measure (F) </plain></SENT>
</text></td></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1"><text><SENT sid="372" pm="."><plain>Cardiovascular </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="373" pm="."><plain>MSVM </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="374" pm="."><plain>74.3% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="375" pm="."><plain>87.6% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="376" pm="."><plain>80.4% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="377" pm="."><plain>WNB </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="378" pm="."><plain>57.3% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="379" pm="."><plain>72.5% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="380" pm="."><plain>63.9% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="381" pm="."><plain>WKNN(3) </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="382" pm="."><plain>60.1% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="383" pm="."><plain>68.6% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="384" pm="."><plain>64.0% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="385" pm="."><plain>EPU </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="386" pm="."><plain>85.2% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="387" pm="."><plain>81.0% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="388" pm="."><plain>84.1% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"><text><SENT sid="389" pm="."><plain>Endocrine </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="390" pm="."><plain>MSVM </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="391" pm="."><plain>83.4% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="392" pm="."><plain>85.2% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="393" pm="."><plain>84.2% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="394" pm="."><plain>WNB </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="395" pm="."><plain>61.3% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="396" pm="."><plain>70.4% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="397" pm="."><plain>65.3% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="398" pm="."><plain>WKNN(3) </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="399" pm="."><plain>64.5% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="400" pm="."><plain>53.1% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="401" pm="."><plain>57.9% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="402" pm="."><plain>EPU </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="403" pm="."><plain>88.1% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="404" pm="."><plain>87.7% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="405" pm="."><plain>87.9% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"><text><SENT sid="406" pm="."><plain>Neurological </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="407" pm="."><plain>MSVM </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="408" pm="."><plain>69.3% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="409" pm="."><plain>83.7% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="410" pm="."><plain>75.8% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="411" pm="."><plain>WNB </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="412" pm="."><plain>61.1% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="413" pm="."><plain>74.4% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="414" pm="."><plain>67.0% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="415" pm="."><plain>WKNN(3) </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="416" pm="."><plain>62.3% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="417" pm="."><plain>67.1% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="418" pm="."><plain>64.6% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="419" pm="."><plain>EPU </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="420" pm="."><plain>78.2% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="421" pm="."><plain>80.4% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="422" pm="."><plain>78.6% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"><text><SENT sid="423" pm="."><plain>Metabolic </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="424" pm="."><plain>MSVM </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="425" pm="."><plain>84.0% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="426" pm="."><plain>91.3% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="427" pm="."><plain>87.4% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="428" pm="."><plain>WNB </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="429" pm="."><plain>68.8% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="430" pm="."><plain>79.9% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="431" pm="."><plain>73.9% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="432" pm="."><plain>WKNN(3) </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="433" pm="."><plain>76.6% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="434" pm="."><plain>78.8% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="435" pm="."><plain>77.6% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="436" pm="."><plain>EPU </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="437" pm="."><plain>83.3% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="438" pm="."><plain>93.9% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="439" pm="."><plain>90.9% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"><text><SENT sid="440" pm="."><plain>Ophthalmological </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="441" pm="."><plain>MSVM </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="442" pm="."><plain>78.4% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="443" pm="."><plain>86.1% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="444" pm="."><plain>81.9% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="445" pm="."><plain>WNB </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="446" pm="."><plain>61.2% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="447" pm="."><plain>78.7% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="448" pm="."><plain>68.8% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="449" pm="."><plain>WKNN(3) </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="450" pm="."><plain>67.3% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="451" pm="."><plain>72.2% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="452" pm="."><plain>69.6% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="453" pm="."><plain>EPU </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="454" pm="."><plain>89.3% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="455" pm="."><plain>81.0% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="456" pm="."><plain>84.7% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"><text><SENT sid="457" pm="."><plain>Cancer </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="458" pm="."><plain>MSVM </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="459" pm="."><plain>73.4% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="460" pm="."><plain>83.9% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="461" pm="."><plain>78.3% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="462" pm="."><plain>WNB </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="463" pm="."><plain>72.5% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="464" pm="."><plain>85.1% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="465" pm="."><plain>78.3% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="466" pm="."><plain>WKNN(3) </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="467" pm="."><plain>76.4% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="468" pm="."><plain>81.0% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="469" pm="."><plain>78.6% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="470" pm="."><plain>EPU </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="471" pm="."><plain>81.2% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="472" pm="."><plain>84.5% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="473" pm="."><plain>82.6% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"><text><SENT sid="474" pm="."><plain>Average performance </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="475" pm="."><plain>MSVM </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="476" pm="."><plain>78.6% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="477" pm="."><plain>86.3% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="478" pm="."><plain>81.3% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="479" pm="."><plain>WNB </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="480" pm="."><plain>63.7% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="481" pm="."><plain>76.8% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="482" pm="."><plain>69.5% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="483" pm="."><plain>WKNN(3) </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="484" pm="."><plain>67.9% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="485" pm="."><plain>70.1% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="486" pm="."><plain>68.7% </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="487" pm="."><plain>EPU </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="488" pm="."><plain>84.2% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="489" pm="."><plain>84.8% </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="490" pm="."><plain>84.8% </plain></SENT>
</text></td></tr></tbody></table></alternatives><table-wrap-foot><fn id="nt102"><label/><p><text><SENT sid="491" pm="."><plain>EPU is compared with its three component classifiers Multi-level Support Vector Machine (MSVM), Weighted Naïve Bayes (WNB) and Weighted K-Nearest Neighbor (KNN) on 6 disease groups. </plain></SENT>
<SENT sid="492" pm="."><plain>WKNN(3) is an instance-based classifier that predicts the class of an unlabeled gene based on its 3 closest labeled genes. </plain></SENT>
</text></p></fn></table-wrap-foot></table-wrap></SecTag><p><text><SENT sid="493" pm="."><plain>Our proposed ensemble learning method EPU is able to achieve 84.8% in terms of F-measure, which is 3.5%, 15.3% and 16.1% better than MSVM, WNB and WKNN respectively. </plain></SENT>
<SENT sid="494" pm="."><plain>Moreover, EPU consistently outperformed all 3 component classifiers for every disease class. </plain></SENT>
<SENT sid="495" pm="."><plain>This strongly demonstrates that EPU can effectively integrate multiple classification models and minimize the overall error rate through dynamically assigning different weights to different classification models. </plain></SENT>
</text></p></sec><sec id="s3c3"><title><text><SENT sid="496" pm="."><plain>Sensitivity study on the parameter η in EPU and parameter k in genetic similarity networks </plain></SENT>
</text></title><p><text><SENT sid="497" pm="."><plain>We perform the sensitivity study for parameter η in EPU and coverage of genetic similarity networks. </plain></SENT>
<SENT sid="498" pm="."><plain>Parameter η is the learning rate in EPU algorithm. </plain></SENT>
<SENT sid="499" pm="."><plain>We perform EPU on six disease groups with η from 0.001 to 0.03. </plain></SENT>
<SENT sid="500" pm="."><plain>The result indicates that step size within 0.001 is small enough to move optimal value point in hypothesis space and our EPU is robust and stable when η is small (Table S3 for the detailed results). </plain></SENT>
<SENT sid="501" pm="."><plain>In addition, we study the effect of the parameter k that determines the number of neighbors of each gene in biological networks. </plain></SENT>
<SENT sid="502" pm="."><plain>The results in Table S4 show that EPU consistently achieved best performance with k in (1, 9). </plain></SENT>
</text></p></sec><sec id="s3c4"><title><text><SENT sid="503" pm="."><plain>Comparing EPU with existing ensemble learning approaches </plain></SENT>
</text></title><p><text><SENT sid="504" pm="."><plain>We also compared our proposed EPU with two existing ensemble approaches, majority vote and weighted majority vote [31], in terms of F-measure across the six disease classes. </plain></SENT>
<SENT sid="505" pm="."><plain>EPU was shown to outperform the existing ensemble methods (see Table S2 for the detailed results), indicating that our proposed EPU is a superior ensemble strategy for integrating multiple classification models for disease gene prediction. </plain></SENT>
</text></p></sec><sec id="s3c5"><title><text><SENT sid="506" pm="."><plain>Predicting novel disease genes for disease groups </plain></SENT>
</text></title><p><text><SENT sid="507" pm="."><plain>To demonstrate novel disease gene prediction using the EPU algorithm, we selected two important disease groups, namely, metabolic and cancer, as detailed case studies. </plain></SENT>
<SENT sid="508" pm="."><plain>For each target disease class, we obtained a set of confirmed disease genes from OMIM and GENECARD as the positive training set, and applied our proposed EPU algorithm to prioritize a novel disease gene from the unlabeled gene set. </plain></SENT>
</text></p><p><text><SENT sid="509" pm="."><plain>We first applied our EPU algorithm to discover novel disease genes for metabolic diseases. </plain></SENT>
<SENT sid="510" pm="."><plain>12 unlabeled genes were detected to be associated with target disease using our algorithm. </plain></SENT>
<SENT sid="511" pm="."><plain>For verification, we searched the literature for evidence that supports the association of these predicted disease genes to metabolic diseases. </plain></SENT>
<SENT sid="512" pm="."><plain>We found that two predicted genes, RHEB and DOK5, have indeed been reported to be associated with metabolic diseases. </plain></SENT>
<SENT sid="513" pm="."><plain>Rheb, a GTP-binding protein, was reported to be inactivated to protect cardiomyocyte during energy deprivation via activation of autophagy. </plain></SENT>
<SENT sid="514" pm="."><plain>This implies that RHEB is a key regulator of autophagy during myocardial ischemia, which has implications in patients with obesity and metabolic syndrome [32]. </plain></SENT>
<SENT sid="515" pm="."><plain>As for DOK5, Tabassum et al. identified that it is a novel candidate disease genes associated with type 2 diabetes, which is a metabolic disorder due to obesity [33]. </plain></SENT>
</text></p><p><text><SENT sid="516" pm="."><plain>Our EPU model also predicted 32 unlabeled genes as candidate genes associated with cancer. </plain></SENT>
<SENT sid="517" pm="."><plain>Seven of them, SIGLEC7, PRDX4, PRDX5, HNRNPL, SRPK1, ABCB10 and PHF10 have been reported to be associated with cancer diseases. Table 3 lists these candidate disease genes and the supporting literature evidence that we have found. </plain></SENT>
</text></p><SecTag type="TABLE"><table-wrap id="pone-0097079-t003" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0097079.t003</object-id><label>Table 3</label><caption><title><text><SENT sid="518" pm="."><plain>Novel cancer-related genes predicted by EPU. </plain></SENT>
</text></title></caption><alternatives><graphic id="pone-0097079-t003-3" xlink:href="pone.0097079.t003"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/></colgroup><thead><tr><td align="left" rowspan="1" colspan="1"><text><SENT sid="519" pm="."><plain>Gene ID </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="520" pm="."><plain>Supported literatures </plain></SENT>
</text></td></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1"><text><SENT sid="521" pm="."><plain>SUGLEC7 </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="522" pm="."><plain>Ito A. et al. (2001) Binding specificity of siglec7 to disialogangliosides of renal cell carcinoma: possible role of disialogangliosides in tumor progression. </plain></SENT>
<SENT sid="523" pm="."><plain>FEBS Lett. </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"><text><SENT sid="524" pm="."><plain>PRDX4 </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="525" pm="."><plain>Lee S.U. et al. (2008) Involvement of peroxiredoxin IV in the 16alpha-hydroxyestrone-induced proliferation of human MCF-7 breast cancer cells. </plain></SENT>
<SENT sid="526" pm="."><plain>Cell Biol Int 32(4): 401–5. </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="527" pm="."><plain>Park H.J. et al. (2008) Proteomic profiling of endothelial cells in human lung cancer. </plain></SENT>
<SENT sid="528" pm="."><plain>J Proteome Res 7(3):1138–50. </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"><text><SENT sid="529" pm="."><plain>PRDX5 </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="530" pm="."><plain>Enqman L., et al. (2003) Thioredoxin reductase and cancer cell growth inhibition by organotellurium compounds that could be selectively incorporated into tumor cells. </plain></SENT>
<SENT sid="531" pm="."><plain>Bioorg Med Chem 11(23): 5091–100. </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="532" pm="."><plain>McNaughton M., et al. (2004) Cyclodextrin-derived diorganyl tellurides as glutathione peroxidase mimics and inhibitors of thioredoxin reductase and cancer cell growth. </plain></SENT>
<SENT sid="533" pm="."><plain>J Med Chem 47(1): 233–9. </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="534" pm="."><plain>Enqman L., et al. (2000) Water-soluble organotellurium compounds inhibit thioredoxin reductase and the growth of human cancer cells. </plain></SENT>
<SENT sid="535" pm="."><plain>Anticancer Drug Des. </plain></SENT>
<SENT sid="536" pm="."><plain>15(5): 323–30. </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"><text><SENT sid="537" pm="."><plain>HNRNPL </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="538" pm="."><plain>Goehe, R.W., et al. (2010) hnRNPL regulates the tumorigenic capacity of lung cancer xenografts in mice via caspase-9 pre-mRNA processing. </plain></SENT>
<SENT sid="539" pm="."><plain>J. </plain></SENT>
<SENT sid="540" pm="."><plain>Clin. </plain></SENT>
<SENT sid="541" pm="."><plain>Inves. </plain></SENT>
<SENT sid="542" pm="."><plain>120(11): 3923. </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="543" pm="."><plain>Hope N.R., et al. (2011) The expression profile of RNA-binding proteins in primary and metastatic colorectal cancer: relationship of heterogeneous nuclear ribonucleoproteins with prognosis. </plain></SENT>
<SENT sid="544" pm="."><plain>Hum Pathol. </plain></SENT>
<SENT sid="545" pm="."><plain>42(3): 393–402. </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"><text><SENT sid="546" pm="."><plain>SRPK1 </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="547" pm="."><plain>Hayes, G.M., et al. (2007) Serine-arginine protein kinase 1 overexpression is associated with tumorigenic imbalance in mitogen-activated protein kinase pathways in breast, colonic, and pancreatic carcinomas. </plain></SENT>
<SENT sid="548" pm="."><plain>Cancer Res. </plain></SENT>
<SENT sid="549" pm="."><plain>67(5): 2972–80. </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"><text><SENT sid="550" pm="."><plain>ABCB10 PHF10 </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="551" pm="."><plain>Tang, L., et al. (2009) Exclusion of ABCB8 and ABCB10 as cancer candidate genes in acute myeloid leukemiaLetter to the Editor. </plain></SENT>
<SENT sid="552" pm="."><plain>Leukemia 23: 1000–2. </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="553" pm="."><plain>Wet M., et al. (2010) Preparation of PHF10 antibody and analysis of PHF10 expression gastric cancer tissues. </plain></SENT>
<SENT sid="554" pm="."><plain>Journal of Xiao Bao Yu Fen Zi Mian Yi Xue 26(9): 874–6. </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1"><text><SENT sid="555" pm="."><plain>Li C., et al. (2012) MicroRNA-409-3p regulates cell proliferation and apoptosis by targeting PHF10 in gastric cancer. </plain></SENT>
<SENT sid="556" pm="."><plain>Cancer Lett 320(2): 187–97. </plain></SENT>
</text></td></tr><tr><td align="left" rowspan="1" colspan="1"><text><SENT sid="557" pm="."><plain>SUGLEC7 </plain></SENT>
</text></td><td align="left" rowspan="1" colspan="1"><text><SENT sid="558" pm="."><plain>Ito A. et al. (2001) Binding specificity of siglec7 to disialogangliosides of renal cell carcinoma: possible role of disialogangliosides in tumor progression. </plain></SENT>
<SENT sid="559" pm="."><plain>FEBS Lett. </plain></SENT>
</text></td></tr></tbody></table></alternatives><table-wrap-foot><fn id="nt103"><label/><p><text><SENT sid="560" pm="."><plain>EPU is used to discover novel cancer related genes from unlabeled gene set. </plain></SENT>
<SENT sid="561" pm="."><plain>The table list 12 candidate genes associated with cancer and their corresponding literature evidences. </plain></SENT>
</text></p></fn></table-wrap-foot></table-wrap></SecTag><p><text><SENT sid="562" pm="."><plain>For other candidate cancer genes without literature evidence support, seven of them, PMM1, SRCIN1, ISY1, KDM4A, CIR1, PPP2R5A and NOL3 have been shown to associate with cancer diseases in GO similarity network, GE similarity network and PPI network. </plain></SENT>
<SENT sid="563" pm="."><plain>From GO similarity network, PMM1 is one of top 5 nearest neighbours of cancer disease gene PPM1D and SCRIN1 is one of neighbours of disease gene CTNNB1. </plain></SENT>
<SENT sid="564" pm="."><plain>In GE similarity network, ISY1 is linked to disease gene P2RX7, KDM4A and CIR1 are interacted with disease genes CTNNB1 and MSH2 respectively, indicating that three suspicious genes are highly correlated with cancer disease genes in terms of gene expression. </plain></SENT>
<SENT sid="565" pm="."><plain>From PPI network, PPP2R5A is directly interacted with two disease genes, BCL2 and TP53, and NOL3 is linking to two disease genes, BAX and CASP8. </plain></SENT>
</text></p></sec></sec></sec></SecTag><SecTag type="DISCUSS,CONCL"><sec id="s4"><title><text><SENT sid="566" pm="."><plain>Conclusions and Discussion </plain></SENT>
</text></title><p><text><SENT sid="567" pm="."><plain>Despite the considerable progress in disease gene discovery, there are still many unknown disease genes that are yet to be characterized. </plain></SENT>
<SENT sid="568" pm="."><plain>Machine learning methods can be used to predict novel disease genes from the confirmed disease genes, based on the observation that genes associated with similar disease phenotypes are likely to share similar biological characteristics. </plain></SENT>
<SENT sid="569" pm="."><plain>However, there are two challenging issues for disease gene predictions. </plain></SENT>
<SENT sid="570" pm="."><plain>Firstly, how to leverage various biological sources during our model building process, which could effectively alleviate the bias issues from the incompleteness and noise in the data. </plain></SENT>
<SENT sid="571" pm="."><plain>Secondly, how to integrate multiple computational models to minimize the potential bias and errors as individual learning methods has their inherent limitations and they could predict accurately for some disease genes but could fail badly for the other ones. </plain></SENT>
<SENT sid="572" pm="."><plain>In this work, we have designed a novel ensemble learning method EPU for predicting disease genes via using a network-based random walk with restart approach on multiple biological networks, and an ensemble classification approach on multiple machine-learned prediction models. </plain></SENT>
<SENT sid="573" pm="."><plain>By using multiple biological data sources, EPU is less susceptible to potential bias, incompleteness and noise in individual data source. </plain></SENT>
<SENT sid="574" pm="."><plain>In this paper, we choose Nearest Neighbor, Naïve Bayes and SVM as three base learning models of EPU due to three reasons: they are the state-of-the-art learning techniques that have been widely used in disease gene identification filed [10] [11] [15] [17] [34]; 2) we are combining PU learning models instead of traditional classification models – we choose the three classification models as they can be easily adapted to build PU learning models; 3) they are quite diverse with learning criterions, so that their complementary nature may contribute a more accurate and robust combinational result. </plain></SENT>
<SENT sid="575" pm="."><plain>By employing an ensemble approach for prediction, EPU also minimizes the inherent limitations of individual prediction models. </plain></SENT>
<SENT sid="576" pm="."><plain>Finally, by employing PU learning techniques for building its ensemble of classification models, EPU is able to treat the unknown genes appropriately as an unlabeled set U (instead of a negative set N) for training, thereby resulting in more robust predictions. </plain></SENT>
<SENT sid="577" pm="."><plain>Experimental evaluations have confirmed the effectiveness of our proposed approach, with our EPU method consistently performing much better than the existing state-of-the-art techniques for disease gene prediction on six disease classes. </plain></SENT>
</text></p><p><text><SENT sid="578" pm="."><plain>As more biological data sources and machine learning classifiers become available in the future, our EPU method can be an effective framework to integrate the additional biological and computational resources for better disease gene predictions. </plain></SENT>
<SENT sid="579" pm="."><plain>For further work, we will explore the inclusion of other biological data sources for disease gene prediction using our framework. </plain></SENT>
<SENT sid="580" pm="."><plain>Given that many machine learning problems in biomedical research do involve ensemble Positive Unlabeled data, we can also adapt our EPU framework to other applications, such as drug-target interaction prediction [35] [36]. </plain></SENT>
</text></p></sec></SecTag><SecTag type="SUPPL"><sec sec-type="supplementary-material" id="s5"><title><text><SENT sid="581" pm="."><plain>Supporting Information </plain></SENT>
</text></title><supplementary-material content-type="local-data" id="pone.0097079.s001"><label>Figure S1</label><caption><p><text><SENT sid="582" pm="."><plain>Procedure of extracting candidate positive set. </plain></SENT>
</text></p><p><text><SENT sid="583" pm="."><plain>(DOCX) </plain></SENT>
</text></p></caption><media xlink:href="pone.0097079.s001.docx"><caption><p><text><SENT sid="584" pm="."><plain>Click here for additional data file. </plain></SENT>
</text></p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0097079.s002"><label>Table S1</label><caption><p><text><SENT sid="585" pm="."><plain>Number of disease genes associated with six disease classes. </plain></SENT>
</text></p><p><text><SENT sid="586" pm="."><plain>(DOCX) </plain></SENT>
</text></p></caption><media xlink:href="pone.0097079.s002.docx"><caption><p><text><SENT sid="587" pm="."><plain>Click here for additional data file. </plain></SENT>
</text></p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0097079.s003"><label>Table S2</label><caption><p><text><SENT sid="588" pm="."><plain>Performance comparison of ensemble methods. </plain></SENT>
</text></p><p><text><SENT sid="589" pm="."><plain>(DOCX) </plain></SENT>
</text></p></caption><media xlink:href="pone.0097079.s003.docx"><caption><p><text><SENT sid="590" pm="."><plain>Click here for additional data file. </plain></SENT>
</text></p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0097079.s004"><label>Table S3</label><caption><p><text><SENT sid="591" pm="."><plain>Effect of parameter η on classification performance of six disease groups. </plain></SENT>
</text></p><p><text><SENT sid="592" pm="."><plain>(DOCX) </plain></SENT>
</text></p></caption><media xlink:href="pone.0097079.s004.docx"><caption><p><text><SENT sid="593" pm="."><plain>Click here for additional data file. </plain></SENT>
</text></p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0097079.s005"><label>Table S4</label><caption><p><text><SENT sid="594" pm="."><plain>Sensitive analysis on biological network noise to disease gene prediction. </plain></SENT>
</text></p><p><text><SENT sid="595" pm="."><plain>(DOCX) </plain></SENT>
</text></p></caption><media xlink:href="pone.0097079.s005.docx"><caption><p><text><SENT sid="596" pm="."><plain>Click here for additional data file. </plain></SENT>
</text></p></caption></media></supplementary-material></sec></SecTag></body><back><SecTag type="REF"><ref-list><title>References</title><ref id="pone.0097079-LpezBigas1"><text><SENT sid="597" pm="."><plain>1 López-BigasN, OuzounisCA (2004) Genome-wide identification of genes likely to be involved in human genetic disease. Nucleic Acids Research 32(10): 3108–3114.15181176 </plain></SENT>
</text></ref><ref id="pone.0097079-Yang1"><text><SENT sid="598" pm="."><plain>2 YangP, LiX, WuM, KwohCK, NgSK (2011) Inferring Gene-Phenotype Associations via Global Protein Complex Network Propagation. PLoS ONE 6(7): e21502.21799737 </plain></SENT>
</text></ref><ref id="pone.0097079-Ala1"><text><SENT sid="599" pm="."><plain>3 AlaU, PiroRM, GrassiE, DamascoC, SilengoL, et al (2008) Prediction of Human Disease Genes by Human-Mouse Conserved Coexpression Analysis. PLoS Comput Biol 4(3): e1000043.18369433 </plain></SENT>
</text></ref><ref id="pone.0097079-Ideker1"><text><SENT sid="600" pm="."><plain>4 IdekerT, SharanR (2008) Protein networks in disease. Genome Research 18: 644–652.18381899 </plain></SENT>
</text></ref><ref id="pone.0097079-PerezIratxeta1"><text><SENT sid="601" pm="."><plain>5 Perez-IratxetaC, BorkP, AndradeMA (2002) Association of genes to genetically inherited diseases using data mining. Nature Genetics 313: 316–319. </plain></SENT>
</text></ref><ref id="pone.0097079-Goh1"><text><SENT sid="602" pm="."><plain>6 GohKI, CusickME, ValleD, ChildsB, VidalM, et al (2007) The human disease network. Proc Natl Acad Sci USA 104(21): 8685–8690.17502601 </plain></SENT>
</text></ref><ref id="pone.0097079-Brunner1"><text><SENT sid="603" pm="."><plain>7 BrunnerHG, Van DrielMA (2004) From syndrome families to functional genomics. Nat Rev Genet 5(7): 545–551.15211356 </plain></SENT>
</text></ref><ref id="pone.0097079-Vanunu1"><text><SENT sid="604" pm="."><plain>8 VanunuO, MaggerO, RuppinE, ShlomiT, SharanR (2010) Associating Genes and Protein Complexes with Disease via Network Propagation. Plos computational biology 6(1): e1000641.20090828 </plain></SENT>
</text></ref><ref id="pone.0097079-Adie1"><text><SENT sid="605" pm="."><plain>9 AdieEA, AdamsRR, EvansKL, PorteousDJ, PickardB (2005) Speeding disease gene discovery by sequence based candidate prioritization. BMC Bioinformatics 6(1): 55.15766383 </plain></SENT>
</text></ref><ref id="pone.0097079-Smalter1"><text><SENT sid="606" pm="."><plain>10Smalter A, Lei SF, Chen X (2007) Human Disease-gene Classification with Integrative Sequence-based and Topological Features of Protein-protein Interaction Networks. </plain></SENT>
<SENT sid="607" pm="."><plain>BIBM. </plain></SENT>
</text></ref><ref id="pone.0097079-Radivojac1"><text><SENT sid="608" pm="."><plain>11 RadivojacP, PengK, ClarkWT, PetersBJ, MohanA, et al (2008) An integrated approach to inferring gene-disease associations in humans. Proteins 72(3): 1030–1037.18300252 </plain></SENT>
</text></ref><ref id="pone.0097079-Mordelet1"><text><SENT sid="609" pm="."><plain>12 MordeletF, VertJP (2011) ProDiGe: Prioritization Of Disease Genes with multitask machine learning from positive and unlabeled examples. BMC Bioinformatics 12(1): 389.21977986 </plain></SENT>
</text></ref><ref id="pone.0097079-Yang2"><text><SENT sid="610" pm="."><plain>13 YangP, LiXL, MeiJP, KwohCK, NgSK (2012) Positive-unlabeled learning for disease gene identification. Bioinformatics 28(20): 2640–2647.22923290 </plain></SENT>
</text></ref><ref id="pone.0097079-Liu1"><text><SENT sid="611" pm="."><plain>14Liu T, Du X, Xu YD, Li M, Wang X (2011) Partially Supervised Text Classification with Multi-Level Examples. </plain></SENT>
<SENT sid="612" pm="."><plain>In AAAI. </plain></SENT>
</text></ref><ref id="pone.0097079-Xu1"><text><SENT sid="613" pm="."><plain>15 XuJZ, LiYJ (2006) Discovering disease-genes by topological features in human protein–protein interaction network. Bioinformatics 22(22): 2800–2805.16954137 </plain></SENT>
</text></ref><ref id="pone.0097079-Khler1"><text><SENT sid="614" pm="."><plain>16 KöhlerS, BauerS, HornD, RobinsonPN (2008) Walking the interactome for prioritization of candidate disease genes. The American Journal of Human Genetics 82(4): 949–958.18371930 </plain></SENT>
</text></ref><ref id="pone.0097079-Linghu1"><text><SENT sid="615" pm="."><plain>17Linghu B, Snitkin ES, Hu Z, Xia Y, DeLisi C (2009) Genome-wide prioritization of disease genes and identification of disease-disease associations from an integrated human functional linkage network. </plain></SENT>
<SENT sid="616" pm="."><plain>Genome Biology 10(9): R91+. </plain></SENT>
</text></ref><ref id="pone.0097079-Schlicker1"><text><SENT sid="617" pm="."><plain>18 SchlickerA, LengauerT, AlbrechtM (2010) Improving disease gene prioritization using the semantic similarity of Gene Ontology terms. Bioinformatics 26(18): i561–i567.20823322 </plain></SENT>
</text></ref><ref id="pone.0097079-Prasad1"><text><SENT sid="618" pm="."><plain>19 PrasadTK, GoelR, KandasamyK, KeerthikumarS, KumarS, et al (2009) Human Protein Reference Database. Nucleic Acids Research 37: 767–772. </plain></SENT>
</text></ref><ref id="pone.0097079-Brown1"><text><SENT sid="619" pm="."><plain>20 BrownKR, JurisicaI (2005) Online predicted human interaction database. Bioinformatics 21(9): 2076–2082.15657099 </plain></SENT>
</text></ref><ref id="pone.0097079-Gene1"><text><SENT sid="620" pm="."><plain>21 Gene Ontology Consortium (2004) The gene ontology database and informatics resource. Nucleic Acid Res 32(1): 258–261. </plain></SENT>
</text></ref><ref id="pone.0097079-Wang1"><text><SENT sid="621" pm="."><plain>22 WangJZ, DuZ, PayattakoolR, PhilipSY, ChenCF (2007) A new method to measure the semantic similarity of GO terms. Bioinformatics 23(10): 1274–1281.17344234 </plain></SENT>
</text></ref><ref id="pone.0097079-McKusick1"><text><SENT sid="622" pm="."><plain>23 McKusickVA (2007) Mendelian Inheritance in Man and Its Online Version, OMIM. Am. </plain></SENT>
<SENT sid="623" pm="."><plain>J. </plain></SENT>
<SENT sid="624" pm="."><plain>Hum. </plain></SENT>
<SENT sid="625" pm="."><plain>Genet. 80: 588–604.17357067 </plain></SENT>
</text></ref><ref id="pone.0097079-VanDriel1"><text><SENT sid="626" pm="."><plain>24 Van DrielMA, BruggemanJ, VriendG, BrunnerHG, LeunissenJA (2006) A text-mining analysis of the human phenome. European Journal of Human Genetics 14(5): 535–542.16493445 </plain></SENT>
</text></ref><ref id="pone.0097079-Flicek1"><text><SENT sid="627" pm="."><plain>25 FlicekP, AmodeMR, BarrelD (2011) Ensemble 2011. Nucleic Acids Res 39(S1): 800–806. </plain></SENT>
</text></ref><ref id="pone.0097079-Deza1"><text><SENT sid="628" pm="."><plain>26Deza E, Deza MM (2009) Encyclopedia of Distances. </plain></SENT>
<SENT sid="629" pm="."><plain>Springer Berline Heidelberg. </plain></SENT>
</text></ref><ref id="pone.0097079-LOVSZ1"><text><SENT sid="630" pm="."><plain>27 LOVÁSZL (1993) Random walks on graphs: a survey. Combinatorics: Paul Erdös is Eighty 2: 1–46. </plain></SENT>
</text></ref><ref id="pone.0097079-Vapnik1"><text><SENT sid="631" pm="."><plain>28Vapnik V (1998) Statistical Learning Theory. </plain></SENT>
<SENT sid="632" pm="."><plain>Wiley, New York. </plain></SENT>
</text></ref><ref id="pone.0097079-Chang1"><text><SENT sid="633" pm="."><plain>29 ChangC, LinC (2011) LIBSVM: a library for support vector machines. ACM Trans Intell Syst Technol 2(3): 27. </plain></SENT>
</text></ref><ref id="pone.0097079-Mitchell1"><text><SENT sid="634" pm="."><plain>30Mitchell TM (1997) Artificial neural network. </plain></SENT>
<SENT sid="635" pm="."><plain>Machine Learning 81–127. </plain></SENT>
</text></ref><ref id="pone.0097079-Kuncheva1"><text><SENT sid="636" pm="."><plain>31Kuncheva LI (2004). </plain></SENT>
<SENT sid="637" pm="."><plain>Combining pattern classifiers: methods and algorithms. </plain></SENT>
<SENT sid="638" pm="."><plain>John Wiley &amp; Sons. </plain></SENT>
</text></ref><ref id="pone.0097079-Sciarretta1"><text><SENT sid="639" pm="."><plain>32 SciarrettaS, ZhaiP, ShaoD, MaejimaY, RobbinsJ, et al (2012) Rheb is a critical regulator of autophagy during myocardial ischemia: pathophysiological implications in obesity and metabolic syndrome. Circulation 125(9): 1134–1146.22294621 </plain></SENT>
</text></ref><ref id="pone.0097079-Tabassum1"><text><SENT sid="640" pm="."><plain>33 TabassumR, MahajanA, ChauhanG, DwivediOP, GhoshS, et al (2010) Evaluation of DOK5 as a susceptibility gene for type 2 diabetes and obesity in North Indian population. BMC Medical Genetics 11: 35.20187968 </plain></SENT>
</text></ref><ref id="pone.0097079-Palaniappan1"><text><SENT sid="641" pm="."><plain>34Palaniappan S, Awang R (2008) Intelligent heart disease prediction system using data mining techniques. </plain></SENT>
<SENT sid="642" pm="."><plain>In Computer Systems and Applications, 2008. </plain></SENT>
<SENT sid="643" pm="."><plain>AICCSA 2008. </plain></SENT>
<SENT sid="644" pm="."><plain>IEEE/ACS International Conference pp.108–115. </plain></SENT>
</text></ref><ref id="pone.0097079-Mei1"><text><SENT sid="645" pm="."><plain>35 MeiJP, KwohCK, YangP, LiXL, ZhengJ (2013) Drug–target interaction prediction by learning from local information and neighbors. Bioinformatics 29(2): 238–245.23162055 </plain></SENT>
</text></ref><ref id="pone.0097079-Mei2"><text><SENT sid="646" pm="."><plain>36Mei JP, Kwoh CK, Yang P, Li XL, Zheng J (2012). </plain></SENT>
<SENT sid="647" pm="."><plain>Globalized bipartite local model for drug-target interaction prediction. </plain></SENT>
<SENT sid="648" pm="."><plain>In Proceedings of the 11th International Workshop on Data Mining in Bioinformatics. pp. </plain></SENT>
<SENT sid="649" pm="."><plain>8–14. </plain></SENT>
</text></ref></ref-list></SecTag></back></article>
