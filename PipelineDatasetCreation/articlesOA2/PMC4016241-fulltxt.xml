<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName JATS-archivearticle1.dtd?><?SourceDTD.Version 1.1?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">4016241</article-id><article-id pub-id-type="pmid">24816822</article-id><article-id pub-id-type="publisher-id">PONE-D-13-53218</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0097079</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Biology and Life Sciences</subject><subj-group><subject>Computational Biology</subject><subj-group><subject>Genome Analysis</subject><subj-group><subject>Genetic Networks</subject></subj-group></subj-group></subj-group><subj-group><subject>Genetics</subject><subj-group><subject>Genetics of Disease</subject></subj-group></subj-group><subj-group><subject>Systems Biology</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Computer and Information Sciences</subject><subj-group><subject>Computerized Simulations</subject></subj-group><subj-group><subject>Computer Modeling</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v2"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Applied Mathematics</subject><subj-group><subject>Algorithms</subject></subj-group></subj-group></subj-group></subj-group></article-categories><title-group><article-title>Ensemble Positive Unlabeled Learning for Disease Gene Identification</article-title><alt-title alt-title-type="running-head">Ensemble PU Learning for Disease Gene Prediction</alt-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Yang</surname><given-names>Peng</given-names></name><xref ref-type="aff" rid="aff1">
<sup>1</sup>
</xref><xref ref-type="corresp" rid="cor1">
<sup>*</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Li</surname><given-names>Xiaoli</given-names></name><xref ref-type="aff" rid="aff1">
<sup>1</sup>
</xref><xref ref-type="corresp" rid="cor1">
<sup>*</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Chua</surname><given-names>Hon-Nian</given-names></name><xref ref-type="aff" rid="aff1">
<sup>1</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Kwoh</surname><given-names>Chee-Keong</given-names></name><xref ref-type="aff" rid="aff2">
<sup>2</sup>
</xref></contrib><contrib contrib-type="author"><name><surname>Ng</surname><given-names>See-Kiong</given-names></name><xref ref-type="aff" rid="aff1">
<sup>1</sup>
</xref></contrib></contrib-group><aff id="aff1">
<label>1</label>
<addr-line>Data Analytics Department, Institute for Infocomm Research (I2R), Agency for Science, Technology and Research (A*STAR), Singapore, Singapore</addr-line>
</aff><aff id="aff2">
<label>2</label>
<addr-line>Bioinformatics Research Centre, School of Computer Engineering, Nanyang Technological University, Singapore, Singapore</addr-line>
</aff><contrib-group><contrib contrib-type="editor"><name><surname>Hernandez-Lemus</surname><given-names>Enrique</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1">
<addr-line>National Institute of Genomic Medicine, Mexico</addr-line>
</aff><author-notes><corresp id="cor1">* E-mail: <email>yangp@i2r.a-star.edu.sg</email> (PY); <email>xlli@i2r.a-star.edu.sg</email> (XL)</corresp><fn fn-type="COI-statement"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><fn fn-type="con"><p>Conceived and designed the experiments: PY XL. Performed the experiments: PY. Analyzed the data: PY H-NC. Contributed reagents/materials/analysis tools: H-NC. Wrote the paper: PY XL. Participated in discussion and improved the method as well as revised the draft: C-KK S-KN. Read and approved the manuscript: PY XL H-NC C-KK S-KN.</p></fn></author-notes><pub-date pub-type="collection"><year>2014</year></pub-date><pub-date pub-type="epub"><day>9</day><month>5</month><year>2014</year></pub-date><volume>9</volume><issue>5</issue><elocation-id>e97079</elocation-id><history><date date-type="received"><day>18</day><month>12</month><year>2013</year></date><date date-type="accepted"><day>14</day><month>4</month><year>2014</year></date></history><permissions><copyright-statement>&#x000a9; 2014 Yang et al</copyright-statement><copyright-year>2014</copyright-year><copyright-holder>Yang et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are properly credited.</license-p></license></permissions><abstract><p>An increasing number of genes have been experimentally confirmed in recent years as causative genes to various human diseases. The newly available knowledge can be exploited by machine learning methods to discover additional unknown genes that are likely to be associated with diseases. In particular, positive unlabeled learning (PU learning) methods, which require only a positive training set <italic>P</italic> (confirmed disease genes) and an unlabeled set <italic>U</italic> (the unknown candidate genes) instead of a negative training set <italic>N</italic>, have been shown to be effective in uncovering new disease genes in the current scenario. Using only a single source of data for prediction can be susceptible to bias due to incompleteness and noise in the genomic data and a single machine learning predictor prone to bias caused by inherent limitations of individual methods. In this paper, we propose an effective PU learning framework that integrates multiple biological data sources and an ensemble of powerful machine learning classifiers for disease gene identification. Our proposed method integrates data from multiple biological sources for training PU learning classifiers. A novel ensemble-based PU learning method EPU is then used to integrate multiple PU learning classifiers to achieve accurate and robust disease gene predictions. Our evaluation experiments across six disease groups showed that EPU achieved significantly better results compared with various state-of-the-art prediction methods as well as ensemble learning classifiers. Through integrating multiple biological data sources for training and the outputs of an ensemble of PU learning classifiers for prediction, we are able to minimize the potential bias and errors in individual data sources and machine learning algorithms to achieve more accurate and robust disease gene predictions. In the future, our EPU method provides an effective framework to integrate the additional biological and computational resources for better disease gene predictions.</p></abstract><funding-group><funding-statement>The authors have no support or funding to report.</funding-statement></funding-group><counts><page-count count="11"/></counts></article-meta></front><body><sec id="s1"><title>Introduction</title><p>While high-throughput genomic studies have led to the discovery of hundreds and thousands of candidate disease genes, the identification of genes involved in specific human diseases has remained a fundamental challenge, requiring time-consuming and expensive experimentation. Computational approaches that can reliably predict novel disease genes from the vast number of unknown genes will provide a useful alternative to speed up the long and arduous searches for the genetic causes of various human disorders.</p><p>Given that an increasing number of genes have been experimentally confirmed over the years as causative genes to various human diseases, it will be useful to develop machine learning methods to identify novel disease genes from the confirmed disease genes as positive training examples, based on the observation that genes associated with similar disease phenotypes are likely to share similar biological characteristics. For example, proteins involved in hereditary diseases tend to be long, with more homologs with distant species, but fewer paralogs within human genome <xref rid="pone.0097079-LpezBigas1" ref-type="bibr">[1]</xref>. They are also likely to attach together to form functional modules such as protein complexes <xref rid="pone.0097079-Yang1" ref-type="bibr">[2]</xref>. In fact, various studies have shown that genes associated with similar disorders tend to demonstrate similar gene expression profiling <xref rid="pone.0097079-Ala1" ref-type="bibr">[3]</xref>, high functional similarities <xref rid="pone.0097079-Ideker1" ref-type="bibr">[4]</xref>
<xref rid="pone.0097079-PerezIratxeta1" ref-type="bibr">[5]</xref> and physical interactions between their gene products <xref rid="pone.0097079-Goh1" ref-type="bibr">[6]</xref>
<xref rid="pone.0097079-Brunner1" ref-type="bibr">[7]</xref>.</p><p>In addition, with disease phenotype similarity data, genes associated with same/similar disease phenotypes are likely to share similar biological functions. Given a phonotype <italic>ph<sub>i</sub></italic>, we can infer its potential disease genes from those disease genes associated with phenotypes <italic>ph<sub>j</sub></italic> (<italic>ph<sub>i</sub></italic> and <italic>ph<sub>j</sub></italic> are very similar) <xref rid="pone.0097079-Vanunu1" ref-type="bibr">[8]</xref>.</p><p>A number of methods above have thus been proposed to prioritize candidate genes based on different kinds of biological data, such as gene sequence data, gene expression profile, evolutionary features, functional annotation data and PPI dataset. Adie <italic>et al.</italic>
<xref rid="pone.0097079-Adie1" ref-type="bibr">[9]</xref> employed a decision tree algorithm based on a variety of genomic sequence and evolutionary features, such as coding sequence length and evolutionary conservation, presence, and closeness of paralogs in the human genome. Topological information on PPI network has also been demonstrated to be useful for disease gene prediction. Smalter <italic>et al.</italic>
<xref rid="pone.0097079-Smalter1" ref-type="bibr">[10]</xref> applied support vector machines (SVM) classifier using PPI topological features in addition to sequence-derived and evolutionary features, while Radivojac <italic>et al.</italic>
<xref rid="pone.0097079-Radivojac1" ref-type="bibr">[11]</xref> built three individual SVM classifiers using three types of features&#x02212;PPI network, protein sequence and protein functional information&#x02212;and then built a final classifier to combine the predictions from three individual classifiers for candidate gene prediction.</p><p>The research work mentioned above employed classical machine learning methods to build a binary classifier where the confirmed disease genes are used as positive training set <italic>P</italic> and unknown genes as negative training set <italic>N</italic>. However, these machine learning techniques hardly perform as well as they could because the negative set <italic>N</italic> that they used contained unconfirmed disease genes (false negatives). In light of aforementioned limitation, recently positive unlabeled learning (PU learning) methods have been proposed for the task by building a classification model in which unknown genes are appropriately treated as an unlabeled set <italic>U</italic> (instead of a negative set <italic>N</italic>). For example, Mordelet <italic>et al.</italic> proposed a bagging method ProDiGe for disease gene prediction. It iteratively choosed random subsets (RS) from <italic>U</italic> and then trained multiple classifiers using bias SVM to discriminate <italic>P</italic> from each subset RS. The multiple classifiers were subsequently aggregated to generate the final classifier <xref rid="pone.0097079-Mordelet1" ref-type="bibr">[12]</xref>. Given that the RS's were likely to contain less noise (unknown disease genes) than the original set <italic>U</italic>, it was able to perform better than classical binary classification models that inappropriately used <italic>U</italic> as negative training data. More recently, Yang <italic>et al.</italic> designed a novel multi-level PU learning algorithm PUDI to build a classifier with better performance for disease gene identification where the unlabeled set <italic>U</italic> was partitioned into multiple positive and negative sets with confidence scores for building the classifier <xref rid="pone.0097079-Yang2" ref-type="bibr">[13]</xref>.</p><p>The prior works have clearly shown that integration of various biological data sources is not only desirable but also essential for robust disease gene prediction, since using only a single source of data for prediction is susceptible to incompleteness and noise in the genomic data. It is also advantageous to employ an ensemble approach for prediction, since using a single machine learning predictor is similarly in risk of potential bias caused by inherent limitations of individual prediction models. In this paper, we propose an effective PU learning framework to integrate multiple biological data sources and an ensemble of powerful machine learning classifiers for disease gene identification. In our proposed framework, we first extract multiple positive and negative samples from unlabeled set <italic>U</italic> through performing random walk with restart on different biological networks. We use three biological networks for this paper: protein interaction network, gene expression similarity network, and GO similarity network. Then, we build multiple independent PU learning models that utilize the extracted positive and negative samples as training data with different confidence scores. Finally, we design a novel ensemble strategy called EPU (Ensemble Positive Unlabeled learning) giving optimized weights to base PU learning models to minimize the overall error rate for accurate disease gene predictions.</p><p>We compare EPU with multiple state-of-the-art techniques, namely, multi-level example based learning <xref rid="pone.0097079-Liu1" ref-type="bibr">[14]</xref>, Smalter's method <xref rid="pone.0097079-Smalter1" ref-type="bibr">[10]</xref>, Xu's method <xref rid="pone.0097079-Xu1" ref-type="bibr">[15]</xref> and ProDiGe method <xref rid="pone.0097079-Mordelet1" ref-type="bibr">[12]</xref>. The experimental results show that EPU outperforms the existing methods significantly for identifying disease genes on 6 disease groups. In addition, our proposed EPU algorithm also achieves better results when it is compared to three base PU learning classifiers, demonstrating that our proposed ensemble-based approach is able to effectively utilize individual classifiers for better performance. Finally, we also conduct a case study to show how our proposed EPU algorithm can discover novel disease genes for endocrine and cancer diseases.</p></sec><sec sec-type="materials|methods" id="s2"><title>Materials and Methods</title><p>In this section, we begin with the description of the experimental data used and briefly introduce how the protein interaction network, gene expression similarity network, and GO similarity network <xref rid="pone.0097079-Khler1" ref-type="bibr">[16]</xref>
<xref rid="pone.0097079-Linghu1" ref-type="bibr">[17]</xref>
<xref rid="pone.0097079-Schlicker1" ref-type="bibr">[18]</xref> are constructed. Then we will present the schema of our proposed EPU algorithm.</p><sec id="s2a"><title>Experimental data and gene network modeling</title><p>In this paper, we have exploited the following biological data human protein interaction data, gene expression data, gene ontology, and phenotype-gene association data.</p><p>
<italic>Human protein interaction data</italic> (PPI) is downloaded from the Human Protein Reference Database (HPRD) <xref rid="pone.0097079-Prasad1" ref-type="bibr">[19]</xref> and Online Predicted Human Interaction Database (OPHID) <xref rid="pone.0097079-Brown1" ref-type="bibr">[20]</xref>. The combined PPI dataset contains 143,939 PPIs among a total of 13,035 human proteins. We build a protein interaction network <italic>G<sub>PPI</sub></italic>&#x0200a;=&#x0200a;(<italic>V<sub>PPI</sub>, E<sub>PPI</sub></italic>) where <italic>V<sub>PPI</sub></italic> represents the set of vertices (proteins) and <italic>E<sub>PPI</sub></italic> denotes all edges (detected pairwise interactions between proteins). <italic>G<sub>PPI</sub></italic> can be represented as its matrix format, i.e. <italic>W<sub>PPI</sub></italic>&#x0200a;=&#x0200a;[w<italic><sub>ij</sub></italic>] where w<italic><sub>ij</sub></italic>&#x0200a;=&#x0200a;1 if the corresponding protein pair <inline-formula><inline-graphic xlink:href="pone.0097079.e001.jpg"/></inline-formula>; 0 otherwise.</p><p>
<italic>Gene expression data</italic> is obtained from RNASeq data which is made publicly available in the EBI ArrayExpress, by the Illumina Human BodyMap 2.0 (<ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE30611">http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE30611</ext-link>). The dataset comprises Fastq reads from the paired-end sequencing of cells from 16 human tissue types, including colon, heart, kidney, white blood cells and so on, using the Illumina HiSeq next generation sequencing platform. This dataset represents the expression values of 17,652 human genes on 16 human tissue types. Suppose gene <italic>g<sub>i</sub></italic> and <italic>g<sub>j</sub></italic> are represented as their gene expression profile vectors (<italic>x<sub>i</sub></italic>
<sub>1</sub>, <italic>x<sub>i</sub></italic>
<sub>2</sub>,&#x02026;, <italic>x<sub>in</sub></italic>) and (<italic>x<sub>j</sub></italic>
<sub>1</sub>, <italic>x<sub>j</sub></italic>
<sub>2</sub>,&#x02026;, <italic>x<sub>jn</sub></italic>) respectively where <italic>x<sub>ik</sub></italic> (<italic>k</italic>&#x0200a;=&#x0200a;1, 2, &#x02026;, <italic>n</italic>) denotes the expression value of gene <italic>i</italic> in the <italic>k</italic>-th tissue. Pearson correlation coefficient is employed to measure the similarity between <italic>g<sub>i</sub></italic> and <italic>g<sub>j</sub></italic>:<disp-formula id="pone.0097079.e002"><graphic xlink:href="pone.0097079.e002.jpg" position="anchor" orientation="portrait"/><label>(1)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="pone.0097079.e003.jpg"/></inline-formula>.</p><p>We build a gene expression similarity network <italic>G<sub>GE</sub></italic>&#x0200a;=&#x0200a;(<italic>V<sub>GE</sub></italic>, <italic>E<sub>GE</sub></italic>), where <inline-formula><inline-graphic xlink:href="pone.0097079.e004.jpg"/></inline-formula> represents a set of genes occurring in the gene expression data and <italic>E<sub>GE</sub></italic> represents a set of edges between the genes in <italic>V<sub>GE</sub></italic>. For each gene <italic>g<sub>i</sub></italic>, we ranked all genes <italic>g<sub>j</sub></italic> in <italic>V<sub>GE</sub></italic> where <italic>i&#x02260;j</italic> according to decreasing order of <italic>sim<sub>GE</sub></italic>(<italic>g<sub>i</sub></italic>, <italic>g<sub>j</sub></italic>), and add an edge (<italic>g<sub>i</sub></italic>, <italic>g<sub>j</sub></italic>) to <italic>E<sub>GE</sub></italic> if <italic>g<sub>j</sub></italic> is in the top 5 of the list. This helps to filter low similarity pairs and potential noise in gene expression data. Then we transform the gene expression network <italic>G<sub>GE</sub></italic> to its matrix format where the edges of two genes are reformatted to their gene expression similarity in <xref ref-type="disp-formula" rid="pone.0097079.e002">equation (1</xref>).</p><p>
<italic>Gene Ontology</italic> (GO, <ext-link ext-link-type="uri" xlink:href="http://www.geneontology.org/">http://www.geneontology.org/</ext-link>) is a set of controlled vocabulary used to annotate genes and gene products <xref rid="pone.0097079-Gene1" ref-type="bibr">[21]</xref>. Gene Ontology provides three sub-ontologies, namely, biological process (<italic>BP</italic>), molecular function (<italic>MF</italic>) and cellular components (<italic>CC</italic>) <xref rid="pone.0097079-Gene1" ref-type="bibr">[21]</xref>. For each gene, we build a feature vector using its annotations from three sub-onotolgies, i.e. {<italic>MF<sub>1</sub></italic>,&#x02026;,<italic>MF<sub>|SMF|</sub></italic>, <italic>BP<sub>1</sub></italic>,&#x02026;,<italic>BP<sub>|SBP|</sub></italic>, <italic>CC<sub>1</sub></italic>,&#x02026;,<italic>CC<sub>|SCC|</sub></italic>}. For example, a gene <italic>g<sub>i</sub></italic> is represented as gene vector <bold><italic>g<sub>i</sub></italic></bold>&#x0200a;=&#x0200a;(<italic>mf<sub>i1</sub></italic>, &#x02026;, <italic>mf<sub>i|SMF|</sub></italic>, <italic>bp<sub>i1</sub></italic>, &#x02026;, <italic>bp<sub>i|SBP|</sub></italic>, <italic>cc<sub>i1</sub></italic>, &#x02026;, <italic>cc<sub>i|SCC|</sub></italic>), where <italic>mf<sub>ij</sub></italic> (similar for <italic>bp<sub>ij</sub></italic>, <italic>cc<sub>ij</sub></italic>) is GO term similarity between <italic>g<sub>i</sub></italic> and the feature <italic>MF<sub>j</sub></italic>. Since the GO terms of <italic>BP</italic>, <italic>MF</italic> and <italic>CC</italic> are organized into DAG structure, we use the computational method in <xref rid="pone.0097079-Wang1" ref-type="bibr">[22]</xref> to measure the similarity of two GO terms. And |<italic>SMF</italic>| is number of selected MF term features. We choose the GO features that could help distinguish disease genes from non-disease genes with strategy in <xref rid="pone.0097079-Yang2" ref-type="bibr">[13]</xref> and top 1000 scored features were selected for each of three feature groups, i.e. <italic>BP</italic>, <italic>MF</italic> and <italic>CC</italic>, respectively. We then build GO similarity network <italic>G<sub>GO</sub></italic>&#x0200a;=&#x0200a;(<italic>V<sub>GO</sub></italic>, <italic>E<sub>GO</sub></italic>), where <italic>V<sub>GO</sub></italic> is the gene set annotated in GO dataset and <italic>E<sub>GO</sub></italic> is a set of edges between the genes in <italic>V<sub>GO</sub></italic>. Similarly to the gene expression similarity network, we keep those top 5 edges which have highest similarities to each gene and other edges. <italic>G<sub>GO</sub></italic> can be represented as its matrix format, i.e. <italic>W<sub>GO</sub></italic>&#x0200a;=&#x0200a;[<italic>w<sub>ij</sub></italic>]. Given a gene <italic>g<sub>i</sub></italic>, if <italic>g<sub>j</sub></italic> is one of top 5 lists of <italic>g<sub>i</sub></italic>, <italic>w<sub>ij</sub></italic> is normalized as:<disp-formula id="pone.0097079.e005"><graphic xlink:href="pone.0097079.e005.jpg" position="anchor" orientation="portrait"/><label>(2)</label></disp-formula>otherwise, <italic>w<sub>ij</sub></italic>&#x0200a;=&#x0200a;0, where <italic>Dis</italic>(<italic>g<sub>i</sub></italic>, <italic>g<sub>j</sub></italic>) denotes Euclidean distance between <italic>g<sub>i</sub></italic> and <italic>g<sub>j</sub></italic> and 0&#x02264;<italic>w<sub>ij</sub></italic>&#x02264;1.</p><sec id="s2a1"><title>Phenotype-gene association data</title><p>4260 phenotype-gene association data, spanning 2659 known disease genes and 3200 disease phenotypes, are obtained from the latest version of OMIM (<ext-link ext-link-type="uri" xlink:href="http://omim.org/">http://omim.org/</ext-link>) <xref rid="pone.0097079-McKusick1" ref-type="bibr">[23]</xref>. Goh <italic>et al.</italic>
<xref rid="pone.0097079-Goh1" ref-type="bibr">[6]</xref> have categorized the 3200 disease phenotypes in OMIM database into 22 disease groups/classes, i.e. Cancer, Metabolic, Neurological, Endocrine, etc, based on the physiological system affected. For example, the Endocrine disease group comprises 62 OMIM phenotypes, including OMIM 241850 (Bamforth-Lazarus syndrome) and OMIM 304800 (Diabetes insipidus, nephrogenic) etc.</p></sec><sec id="s2a2"><title>Phenotype similarity network</title><p>Disease phenotype similarity network <xref rid="pone.0097079-VanDriel1" ref-type="bibr">[24]</xref>, is defined as <italic>G<sub>PH</sub></italic>&#x0200a;=&#x0200a;(<italic>V<sub>PH</sub></italic>, <italic>E<sub>PH</sub></italic>), where <italic>V<sub>PH</sub></italic> denotes the set of disease phenotypes and <italic>E<sub>PH</sub></italic> denotes relevant phenotype pairs. Disease phenotypes in <italic>V<sub>PH</sub></italic> are represented as feature vectors in which feature terms are Medical Subject Headings (MeSH) controlled vocabulary, and phenotype similarities in <italic>E<sub>PH</sub></italic> are evaluated underline concept relevance and frequency of MeSH terms appearing in text description of OMIM documents. According to Vanunu <italic>et al.</italic>
<xref rid="pone.0097079-Vanunu1" ref-type="bibr">[8]</xref>, phenotype pairs with high similarities are regarded as informative and reliable. Therefore, we apply logistic function to filter out low phenotypic similarities in <italic>E<sub>PH</sub></italic>, following <xref rid="pone.0097079-Yang1" ref-type="bibr">[2]</xref>
<xref rid="pone.0097079-Vanunu1" ref-type="bibr">[8]</xref>.</p></sec></sec><sec id="s2b"><title>The proposed technique EPU</title><p>The schema of our EPU algorithm is presented in <xref ref-type="fig" rid="pone-0097079-g001">Figure 1</xref>. EPU first selects candidate positives from positive genes and reliable negatives from unlabeled genes. It then builds three gene similarity networks using PPI data, gene expression data and Gene Ontology data and applies random walk on the three networks to propagate weights to unlabeled genes that reflect likelihoods of belonging to positive/negative class. We then exploit the weighted genes to build three diverse classification models to predict &#x0201c;soft&#x0201d; labels for test genes. Finally, an ensemble learning algorithm combines the prediction results from the classifiers to make a final prediction for the classification of the unknown test gene.</p><fig id="pone-0097079-g001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0097079.g001</object-id><label>Figure 1</label><caption><title>Overall schema of EPU learning algorithm.</title><p>EPU is a framework that utilizes positive and &#x02018;weighted&#x02019; unlabeled examples to build an ensemble classifier for disease gene identification. First of all, EPU extracts candidate positives (CP) and reliable negatives (RN) from unlabeled set. Then it applies random walk algorithm to weight remaining unlabeled genes on genetic networks. To achieve reliable and robust measure on U, EPU consults three biological networks, PPI network, GO similarity network and Gene expression network. After obtained ensemble weighted genes, EPU builds three PU learning classifiers. Finally, a novel ensemble strategy is applied to combines the outputs from these classifiers to make final predictions.</p></caption><graphic xlink:href="pone.0097079.g001"/></fig><p>Suppose all disease genes from OMIM are stored into a disease gene set <italic>DIS</italic>. All the other genes that are not a member of <italic>DIS</italic> will be treated as unknown/unlabeled genes and be stored into a set <italic>UG</italic> (contains <italic>16,570</italic> genes) <xref rid="pone.0097079-Flicek1" ref-type="bibr">[25]</xref>. Each gene in <italic>DIS</italic> and <italic>UG</italic> is represented as a feature vector, namely, <inline-formula><inline-graphic xlink:href="pone.0097079.e006.jpg"/></inline-formula> where <italic>m</italic> is the total number of features from GO terms, protein domains and PPI topological features, following our previous work <xref rid="pone.0097079-Yang2" ref-type="bibr">[13]</xref>.</p><p>In the next section, we describe how to predict novel disease genes given the confirmed disease genes for a particular disease or disorder. The confirmed disease genes for the given disorder group are treated as <italic>positive set P</italic> (<italic>P</italic>
<inline-formula><inline-graphic xlink:href="pone.0097079.e007.jpg"/></inline-formula>
<italic>DIS</italic>) while randomly selected unknown genes from <italic>UG</italic> are treated as <italic>unlabeled set U</italic> (<italic>U</italic>
<inline-formula><inline-graphic xlink:href="pone.0097079.e008.jpg"/></inline-formula>
<italic>UG</italic>, |<italic>U</italic>|&#x0200a;=&#x0200a;|<italic>P</italic>|), following the settings in <xref rid="pone.0097079-Adie1" ref-type="bibr">[9]</xref>
<xref rid="pone.0097079-Smalter1" ref-type="bibr">[10]</xref>
<xref rid="pone.0097079-Xu1" ref-type="bibr">[15]</xref>.</p></sec><sec id="s2c"><title>Weighting unlabeled genes by integrating multiple biological evidences</title><p>Given a particular disease class and its known associated disease genes, we first build the training data sets for machine learning by prioritizing the candidate positives and reliable negatives based on their similarity to the query disease class. We build three gene similarity networks using PPI, gene expression and GO as described above, and perform a random walk with restart algorithm on these three gene similarity networks to estimate the likelihood of the unlabeled genes belonging to disease class or non-disease class. The details are as follows.</p><sec id="s2c1"><title>Extracting candidate positives and reliable negatives</title><p>As a typical positive set <italic>P</italic> is relatively small, we want to find a set of candidate positive genes <italic>CP</italic> to complement <italic>P</italic>. Given that recent studies have shown that similar phenotypes are often caused by functionally related disease genes <xref rid="pone.0097079-Ideker1" ref-type="bibr">[4]</xref>
<xref rid="pone.0097079-Goh1" ref-type="bibr">[6]</xref>, we could populate the set of candidate positive genes <italic>CP</italic> with genes associated to similar/relevant phenotypes, based on the principle of guilt-by-association. In other words, given a query disease group/class, we can use its associated phenotypes to uncover similar disease phenotypes, as shown in <xref ref-type="supplementary-material" rid="pone.0097079.s001">Figure S1</xref>.</p><p>Having identified the candidate positive genes <italic>CP</italic>, let us now describe how to extract <italic>reliable negative</italic> gene set <italic>RN</italic>. We consider reliable negatives as those unlabeled genes that are very different from positive set <italic>P</italic>. To identify such genes, we first build a &#x0201c;positive representative vector&#x0201d; (<italic>pr</italic>) by summing up gene vectors in <italic>P</italic> and normalizing it. Then, we compute the average <italic>Euclidean distance</italic>
<xref rid="pone.0097079-Deza1" ref-type="bibr">[26]</xref> of every unlabeled gene <italic>g<sub>i</sub></italic> in <italic>U</italic> from <italic>pr</italic>. To extract the reliable negative genes for <italic>RN</italic>, we regard an unlabeled gene <italic>g<sub>i</sub></italic> as a member of <italic>RN</italic> if its distance from <italic>pr</italic> is longer than the average distance (of all the genes in <italic>U</italic>) from <italic>pr</italic>, formalized as follows:<disp-formula id="pone.0097079.e009"><graphic xlink:href="pone.0097079.e009.jpg" position="anchor" orientation="portrait"/><label>(3)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="pone.0097079.e010.jpg"/></inline-formula> is the Euclidean distance between gene <italic>g<sub>i</sub></italic> and positive representative vector <italic>pr</italic>. We compute an average distance <inline-formula><inline-graphic xlink:href="pone.0097079.e011.jpg"/></inline-formula> of all the unlabeled gene in <italic>U</italic> from <italic>pr</italic> as: <inline-formula><inline-graphic xlink:href="pone.0097079.e012.jpg"/></inline-formula>
</p></sec><sec id="s2c2"><title>Ensemble weighted unlabeled genes via performing label propagation on multiple networks</title><p>We now have the given positive set <italic>P</italic>, a candidate positive set <italic>CP</italic>, a reliable negative set <italic>RN</italic> and a remaining unlabeled set <inline-formula><inline-graphic xlink:href="pone.0097079.e013.jpg"/></inline-formula> for machine learning. To build a robust classification model, we will extract those genes with reliable labels that are near the decision boundary between the positive and negative classes. We adapt the Random Walk with Restart algorithm <xref rid="pone.0097079-LOVSZ1" ref-type="bibr">[27]</xref> to perform flow propagation which spreads the label information from <italic>P</italic>, <italic>CP</italic> and <italic>RN</italic> to the unlabeled genes in <inline-formula><inline-graphic xlink:href="pone.0097079.e014.jpg"/></inline-formula> on the biological networks that we have constructed, namely the PPI network <italic>G<sub>PPI</sub></italic>, the GO similarity network <italic>G<sub>GO</sub></italic> and the gene expression similarity network <italic>G<sub>GE</sub></italic> as described earlier.</p><p>Formally, let <italic>R<sub>0</sub></italic> be an initialization vector where primitive scores are assigned to all genes in three networks to indicate the genes' potential classification labels. Let <italic>p<sub>0</sub></italic>, <inline-formula><inline-graphic xlink:href="pone.0097079.e015.jpg"/></inline-formula> and <italic>n<sub>0</sub></italic> denote the initial values for genes in <italic>P</italic>, <italic>CP</italic> and <italic>RN</italic> respectively, as follows. The genes <inline-formula><inline-graphic xlink:href="pone.0097079.e016.jpg"/></inline-formula> are all given a score <italic>p<sub>0</sub></italic>(<italic>g<sub>i</sub></italic>)&#x0200a;=&#x0200a;+1, indicating their disease gene status. Each candidate positive gene <inline-formula><inline-graphic xlink:href="pone.0097079.e017.jpg"/></inline-formula> is assigned a score that computes its maximal phenotypic similarity to the known disease genes in <italic>P</italic>,<inline-formula><inline-graphic xlink:href="pone.0097079.e018.jpg"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="pone.0097079.e019.jpg"/></inline-formula> denotes disease phenotypes caused by gene <italic>g<sub>i</sub></italic>, and <italic>PH</italic>(<italic>P</italic>) denotes disease phenotypes caused by disease set <italic>P</italic>. For genes in reliable negative set <italic>RN</italic>, to balance total amount of flows between positive genes and negative genes, the initial score for negative gene <italic>g<sub>i</sub></italic> is assigned with<disp-formula id="pone.0097079.e020"><graphic xlink:href="pone.0097079.e020.jpg" position="anchor" orientation="portrait"/><label>(4)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="pone.0097079.e021.jpg"/></inline-formula> is a total amount of positive gene set. The remaining unlabeled genes in <inline-formula><inline-graphic xlink:href="pone.0097079.e022.jpg"/></inline-formula> are assigned an initial score of 0.</p><p>For each of the three biological networks <italic>G<sub>PPI</sub></italic>, <italic>G<sub>GE</sub></italic> and <italic>G<sub>GO</sub></italic>, prior influence from the seed nodes in <italic>P</italic>, <italic>CP</italic> and <italic>RN</italic> are propagated to their direct neighbors, and then continue to spread to other adjacent nodes iteratively across the network. Given <italic>R<sub>0</sub></italic> the initial score vector (step 0), <italic>R<sub>t</sub></italic>, the score vector at step <italic>t</italic>, can be calculated as follows:<disp-formula id="pone.0097079.e023"><graphic xlink:href="pone.0097079.e023.jpg" position="anchor" orientation="portrait"/><label>(5)</label></disp-formula>where <italic>R<sub>1</sub></italic>&#x0200a;=&#x0200a;<italic>R<sub>0</sub></italic> and <italic>W</italic>&#x0200a;=&#x0200a;<italic>D<sup>&#x02212;1</sup>W</italic> is a normalized format of matrix <italic>W</italic>, <inline-formula><inline-graphic xlink:href="pone.0097079.e024.jpg"/></inline-formula>. Here <italic>D</italic> is the diagonal matrix and <inline-formula><inline-graphic xlink:href="pone.0097079.e025.jpg"/></inline-formula>. <italic>&#x003b1;</italic> represents the percentage of flow back to original seed nodes in <italic>P</italic>, <italic>CP</italic> and <italic>RN</italic> during each iteration. The default value of 0.7 is used for <italic>&#x003b1;</italic>, following <xref rid="pone.0097079-Khler1" ref-type="bibr">[16]</xref>.</p><p>Eventually, the information flow will converge to a steady state <xref rid="pone.0097079-LOVSZ1" ref-type="bibr">[27]</xref>. In our case, the Random Walk with Restart algorithm will stop its iterative process when the difference between two steps <italic>R<sub>t</sub></italic> and <italic>R<sub>t-1</sub></italic> is less than 10<sup>&#x02212;6</sup>
<xref rid="pone.0097079-Khler1" ref-type="bibr">[16]</xref>, measured by <italic>L1 norm</italic>. The scores for unlabeled genes from the three gene networks are combined into one <italic>integrated score</italic>:<disp-formula id="pone.0097079.e026"><graphic xlink:href="pone.0097079.e026.jpg" position="anchor" orientation="portrait"/><label>(6)</label></disp-formula>where <italic>R<sub>t</sub></italic>(<italic>g</italic>,<italic>W<sub>PPI</sub></italic>), <italic>R<sub>t</sub></italic>(<italic>g</italic>,<italic>W<sub>GO</sub></italic>) and <italic>R<sub>t</sub></italic>(<italic>g</italic>,<italic>W<sub>GE</sub></italic>) are the scores for gene <italic>g</italic> in the PPI, GO similarity and gene expression similarity networks respectively.</p></sec></sec><sec id="s2d"><title>Ensemble positive unlabeled learning EPU</title><p>Next, we describe how to build three separate PU learning classification models Support Vector Machine <italic>SVM</italic>, K-Nearest Neighbor, and Na&#x000ef;ve Bayes classifier&#x02212;to classify genes into two classes <italic>C</italic>&#x0200a;=&#x0200a;{<italic>+</italic>, <italic>&#x02212;</italic>}, where &#x02018;<italic>+</italic>&#x02019; denotes positive/disease class and &#x02018;<italic>&#x02212;</italic>&#x02019; presents negative/non-disease class.</p><sec id="s2d1"><title>PU learning model 1: Weighted K-Nearest Neighbor (WKNN)</title><p>KNN is an instance based learning method, which classifies an unknown test gene based on the class labels of its top <italic>K</italic> nearest training example genes, i.e. based on the majority class vote of its nearest <italic>K</italic> neighbors. The distance between the test gene and other training examples can be computed using common distance metrics such as Euclidean distance. Given a test gene <italic>g<sub>i</sub></italic> and its <italic>k</italic> nearest neighbor set <italic>D<sub>i</sub></italic>, we divide <italic>D<sub>i</sub></italic> into positive and negative training subsets, namely <italic>D<sub>i+</sub></italic>&#x0200a;=&#x0200a;{<italic>g|Int_score(g)&#x02265;0</italic>, <italic>g</italic>&#x02208;<italic>D<sub>i</sub></italic>} and <italic>D<sub>i-</sub></italic>&#x0200a;=&#x0200a;{<italic>g|Int_score(g)&#x0003c;0</italic>, <italic>g</italic>&#x02208;<italic>D<sub>i</sub></italic>} based on these neighbors' integrated scores. The conditional probability of the test gene <italic>g<sub>i</sub></italic> with respect to disease (+)/non-disease class (&#x02212;), is measured as<disp-formula id="pone.0097079.e027"><graphic xlink:href="pone.0097079.e027.jpg" position="anchor" orientation="portrait"/><label>(7)</label></disp-formula>
</p><p>Note that weighted KNN accumulates both positive and negative integrated scores in <italic>D<sub>i</sub></italic> and estimates the probability of <italic>g<sub>i</sub></italic> belonging to positive (or negative) class based on the accumulated scores in that class.</p></sec><sec id="s2d2"><title>PU learning model 2: Weighted Na&#x000ef;ve Bayes (WNB)</title><p>Given a test gene <italic>g<sub>i</sub></italic>, the probability that gene <italic>g<sub>i</sub></italic> belongs to a class <italic>c<sub>j</sub></italic> (<inline-formula><inline-graphic xlink:href="pone.0097079.e028.jpg"/></inline-formula>) can be computed using Bayes' theorem as:<disp-formula id="pone.0097079.e029"><graphic xlink:href="pone.0097079.e029.jpg" position="anchor" orientation="portrait"/><label>(8)</label></disp-formula>where the probability <inline-formula><inline-graphic xlink:href="pone.0097079.e030.jpg"/></inline-formula> is a constant for the positive and negative classes. Here, we define the prior probabilities of the positive and negative classes as 0.5, i.e. <italic>P</italic>(<italic>Y</italic>&#x0200a;=&#x0200a;+)&#x0200a;=&#x0200a;<italic>P</italic>(<italic>Y</italic>&#x0200a;=&#x0200a;&#x02212;)&#x0200a;=&#x0200a;0.5. Given a gene vector <inline-formula><inline-graphic xlink:href="pone.0097079.e031.jpg"/></inline-formula>, the conditional probability of feature <italic>f<sub>k</sub></italic> associated with class <italic>c<sub>j</sub></italic>, denoted as <italic>P</italic>(<italic>f<sub>k</sub></italic>|<italic>Y</italic>&#x0200a;=&#x0200a;<italic>c<sub>j</sub></italic>), is calculated as:<disp-formula id="pone.0097079.e032"><graphic xlink:href="pone.0097079.e032.jpg" position="anchor" orientation="portrait"/><label>(9)</label></disp-formula>where <italic>g</italic>(<italic>f<sub>k</sub></italic>) is the value of feature <italic>f<sub>k</sub></italic> in gene vector <inline-formula><inline-graphic xlink:href="pone.0097079.e033.jpg"/></inline-formula>, <inline-formula><inline-graphic xlink:href="pone.0097079.e034.jpg"/></inline-formula>is defined as either <inline-formula><inline-graphic xlink:href="pone.0097079.e035.jpg"/></inline-formula> or <inline-formula><inline-graphic xlink:href="pone.0097079.e036.jpg"/></inline-formula>, depending on <italic>c<sub>j</sub></italic> is positive class (+) or negative class (&#x02212;).</p><p>By assuming that the probabilities of features are independent given the class <italic>Y</italic>&#x0200a;=&#x0200a;<italic>c<sub>j</sub></italic>, we obtain the Na&#x000ef;ve Bayes classifier:<disp-formula id="pone.0097079.e037"><graphic xlink:href="pone.0097079.e037.jpg" position="anchor" orientation="portrait"/><label>(10)</label></disp-formula>
</p></sec><sec id="s2d3"><title>PU learning model 3: Multi-level Support Vector Machine (MSVM)</title><p>Based on the integrated score <italic>Int_score</italic>(<italic>g</italic>), we further partition the unlabeled genes <inline-formula><inline-graphic xlink:href="pone.0097079.e038.jpg"/></inline-formula> into three parts: likely positive set <italic>LP</italic> (genes get higher positive integrated scores), likely negative set <italic>LN</italic> (genes get lower negative integrated scores) and weak negative set <italic>WN</italic> (remaining genes) using the following criteria:<disp-formula id="pone.0097079.e039"><graphic xlink:href="pone.0097079.e039.jpg" position="anchor" orientation="portrait"/><label>(11)</label></disp-formula>
</p><p>We then build a multi-level classifier based on positive training set <italic>P</italic>, reliable negative set <italic>RN</italic>, and three newly generated sets <italic>LP</italic>, <italic>LN</italic>, and <italic>WN</italic>, via weighted support vector machine technique <xref rid="pone.0097079-Vapnik1" ref-type="bibr">[28]</xref>
<xref rid="pone.0097079-Chang1" ref-type="bibr">[29]</xref>, to take into account of the inherently different levels of trustworthiness of labels in the five gene set.</p><p>The objective function of Weighted SVM can be defined as <xref rid="pone.0097079-Liu1" ref-type="bibr">[14]</xref>:<disp-formula id="pone.0097079.e040"><graphic xlink:href="pone.0097079.e040.jpg" position="anchor" orientation="portrait"/><label>(12)</label></disp-formula>
</p><p>Subject to: <inline-formula><inline-graphic xlink:href="pone.0097079.e041.jpg"/></inline-formula> where the values of parameters <inline-formula><inline-graphic xlink:href="pone.0097079.e042.jpg"/></inline-formula>, <inline-formula><inline-graphic xlink:href="pone.0097079.e043.jpg"/></inline-formula>, <inline-formula><inline-graphic xlink:href="pone.0097079.e044.jpg"/></inline-formula>, <inline-formula><inline-graphic xlink:href="pone.0097079.e045.jpg"/></inline-formula> and <inline-formula><inline-graphic xlink:href="pone.0097079.e046.jpg"/></inline-formula> can be decided by using cross-validation techniques. Finally, we apply our MSVM model <inline-formula><inline-graphic xlink:href="pone.0097079.e047.jpg"/></inline-formula> to compute the probability of test gene <italic>g<sub>i</sub></italic> belonging to class <italic>c<sub>j</sub></italic> (<inline-formula><inline-graphic xlink:href="pone.0097079.e048.jpg"/></inline-formula>) for its classification.</p><p>Note that while the candidate positive set <italic>CP</italic> plays a role in assigning the genes in <italic>U</italic> - <italic>RN</italic> to one of the 3 subsets <italic>LP</italic>, <italic>LN</italic> and <italic>WN</italic>, it does not overlap with the training set <inline-formula><inline-graphic xlink:href="pone.0097079.e049.jpg"/></inline-formula> and hence is not used in the construction of the <italic>MSVM</italic> model.</p></sec><sec id="s2d4"><title>Ensemble-based algorithm for integration of individual classifiers</title><p>In order to perform more robust classification, we design a novel ensemble learning model to integrate the three classification models constructed above.</p><p>Suppose <inline-formula><inline-graphic xlink:href="pone.0097079.e050.jpg"/></inline-formula> denotes the probability of gene <inline-formula><inline-graphic xlink:href="pone.0097079.e051.jpg"/></inline-formula> belonging to class <italic>c</italic> as predicted by the <italic>j<sup>th</sup></italic> classifier. We can organize the genes in <italic>D</italic> in the following matrix:<disp-formula id="pone.0097079.e052"><graphic xlink:href="pone.0097079.e052.jpg" position="anchor" orientation="portrait"/><label>(13)</label></disp-formula>where <italic>k</italic> is the number of individual classifiers (here, <italic>k</italic>&#x0200a;=&#x0200a;3), and |<italic>D</italic>| is the size of training set <italic>D</italic>.</p><p>Our ensemble model <inline-formula><inline-graphic xlink:href="pone.0097079.e053.jpg"/></inline-formula> integrates the outputs from the multiple classification models as follows:<disp-formula id="pone.0097079.e054"><graphic xlink:href="pone.0097079.e054.jpg" position="anchor" orientation="portrait"/><label>(14)</label></disp-formula>where <inline-formula><inline-graphic xlink:href="pone.0097079.e055.jpg"/></inline-formula> is a weight vector that indicates the importance of individual models. The final output value &#x0201c;1&#x0201d; denotes disease/positive class and &#x02018;&#x02212;1&#x02019; denotes non-disease/negative class.</p><p>The classifier weight <inline-formula><inline-graphic xlink:href="pone.0097079.e056.jpg"/></inline-formula> can be learned from training set <italic>D</italic> as follows. We define <inline-formula><inline-graphic xlink:href="pone.0097079.e057.jpg"/></inline-formula> as training error of the hypothesis of our ensemble model:<disp-formula id="pone.0097079.e058"><graphic xlink:href="pone.0097079.e058.jpg" position="anchor" orientation="portrait"/><label>(15)</label></disp-formula>where <italic>y<sub>i</sub></italic> (<italic>y<sub>i</sub></italic>
<inline-formula><inline-graphic xlink:href="pone.0097079.e059.jpg"/></inline-formula>{&#x02212;1,1}) and <italic>o<sub>i</sub></italic> (<italic>o<sub>i</sub></italic>
<inline-formula><inline-graphic xlink:href="pone.0097079.e060.jpg"/></inline-formula>{&#x02212;1,1}) are the actual class and predicted class by our ensemble model for training gene <inline-formula><inline-graphic xlink:href="pone.0097079.e061.jpg"/></inline-formula> respectively. <inline-formula><inline-graphic xlink:href="pone.0097079.e062.jpg"/></inline-formula> is a linear square error function that evaluates the difference between <italic>y<sub>i</sub></italic> and <italic>o<sub>i</sub></italic>. We minimize <inline-formula><inline-graphic xlink:href="pone.0097079.e063.jpg"/></inline-formula> to guarantee the classification output <italic>o</italic> with minimal error rate and calculate the weight vector <inline-formula><inline-graphic xlink:href="pone.0097079.e064.jpg"/></inline-formula>.</p><p>Here, gradient decent is applied to search the probable weight vectors in error surface. The gradient of <italic>E</italic> for <inline-formula><inline-graphic xlink:href="pone.0097079.e065.jpg"/></inline-formula>, denoted as <inline-formula><inline-graphic xlink:href="pone.0097079.e066.jpg"/></inline-formula>, is the derivative of <italic>E</italic> with respect to each component of the vector<inline-formula><inline-graphic xlink:href="pone.0097079.e067.jpg"/></inline-formula>. From above equation, we obtain each component of <inline-formula><inline-graphic xlink:href="pone.0097079.e068.jpg"/></inline-formula> as follows:<disp-formula id="pone.0097079.e069"><graphic xlink:href="pone.0097079.e069.jpg" position="anchor" orientation="portrait"/><label>(16)</label></disp-formula>
</p><p>The following training rule guarantees that <inline-formula><inline-graphic xlink:href="pone.0097079.e070.jpg"/></inline-formula> is adjusted in the direction of steepest descent along the error surface: <inline-formula><inline-graphic xlink:href="pone.0097079.e071.jpg"/></inline-formula>, where <inline-formula><inline-graphic xlink:href="pone.0097079.e072.jpg"/></inline-formula>. <italic>&#x003b7;</italic> is a small positive constant, called learning rate, to determine the step size in gradient decent exploration. We set <italic>&#x003b7;</italic>&#x0200a;=&#x0200a;0.001, following previous work <xref rid="pone.0097079-Mitchell1" ref-type="bibr">[30]</xref>. The negative gradient <inline-formula><inline-graphic xlink:href="pone.0097079.e073.jpg"/></inline-formula> gives the direction of steepest decrease. According to equations above, we update the gradient descent rule as follows:<disp-formula id="pone.0097079.e074"><graphic xlink:href="pone.0097079.e074.jpg" position="anchor" orientation="portrait"/><label>(17)</label></disp-formula>
</p><p>The overall ensemble learning method is summarized in <xref ref-type="fig" rid="pone-0097079-g002">Figure 2</xref>. First, we assign an initial random weight vector for <inline-formula><inline-graphic xlink:href="pone.0097079.e075.jpg"/></inline-formula>. The ensemble model is then applied to all training genes and each weight is then updated by adding <inline-formula><inline-graphic xlink:href="pone.0097079.e076.jpg"/></inline-formula> computed according to <xref ref-type="disp-formula" rid="pone.0097079.e074">equation (17</xref>) above. This process is repeated until <inline-formula><inline-graphic xlink:href="pone.0097079.e077.jpg"/></inline-formula> converges. Note that if <italic>&#x003b7;</italic> is a large number, the search exploration might overstep the minimum point in the error surface rather than settling into it. Therefore, the value of <italic>&#x003b7;</italic> should be gradually reduced as the number of iteration grows.</p><fig id="pone-0097079-g002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0097079.g002</object-id><label>Figure 2</label><caption><title>Ensemble learning algorithm.</title></caption><graphic xlink:href="pone.0097079.g002"/></fig></sec></sec></sec><sec id="s3"><title>Experimental Results</title><p>For evaluation, we benchmark our proposed EPU algorithm against four state-of-the-art techniques for disease gene prediction: PUDI method, Smalter's method, Xu's method and ProDiGe. In addition, we also compare the performance of EPU with its base learning models, namely MSVM, WKNN and WNB. Finally, we demonstrate <italic>novel</italic> disease gene prediction using the EPU algorithm.</p><sec id="s3a"><title>Experimental settings</title><p>We use the disease classes with at least 50 confirmed disease genes from the 21 specific disease classes in <xref rid="pone.0097079-Goh1" ref-type="bibr">[6]</xref> for evaluating our classification algorithm. There are six such disease classes: cardiovascular disease, endocrine disease, cancer disease, metabolic disease, neurological disease, and ophthalmological disease (See <xref ref-type="supplementary-material" rid="pone.0097079.s002">Table S1</xref> for the exact numbers of disease genes for each class). Given a particular disease class, the positive set <italic>P</italic> consists of all its confirmed disease genes, while the unlabeled set <italic>U</italic> is formed by randomly selecting from the genes that are not known to be associated with any disease such that |<italic>P</italic>|&#x0200a;=&#x0200a;|<italic>U</italic>|, following the setting in <xref rid="pone.0097079-Adie1" ref-type="bibr">[9]</xref>
<xref rid="pone.0097079-Smalter1" ref-type="bibr">[10]</xref>
<xref rid="pone.0097079-Xu1" ref-type="bibr">[15]</xref>. To avoid bias in sampling, we randomly select 10 groups of unlabeled set <italic>U</italic>. All experimental evaluations of the classification models are done on identical groups of training and test data, and we report the average performance over the 10 groups of (<italic>P</italic>+<italic>U</italic>) sets. To evaluate the performance of our algorithm, 3 fold cross validation is applied where two folds in <italic>P+U</italic> as the training set build classifier while remaining one fold is the test set. Next, positive training genes in <italic>P</italic> are used as seed nodes on multiple genetic networks to weight unlabeled training genes in <italic>U</italic> via flow propagation. Then, to obtain the &#x02018;soft&#x02019; classes of training genes from component learning models, leave-one-out cross-validation (LOOCV) is used on 2 fold training samples, from which each training sample is singled out to evaluate its &#x02018;soft&#x02019; classes by component classifiers (MSVM, WKNN and WNB), which are built on the other training samples. After LOOCV, these training samples with the &#x02018;soft&#x02019; classes are as input data to build an ensemble learning model (as shown in <xref ref-type="fig" rid="pone-0097079-g002">Figure 2</xref>) to predict 1 fold test fold. The average results on 3&#x000d7;10 groups of (<italic>P+U</italic>) sets are reported on experimental part.</p></sec><sec id="s3b"><title>Evaluation metrics</title><p>We use precision, recall, and F-measure to measure the performance of our classification models on each of the six disease classes. The F-measure is the harmonic mean of precision (denoted as <italic>p</italic>) and recall (denoted as <italic>r</italic>), defined as<disp-formula id="pone.0097079.e078"><graphic xlink:href="pone.0097079.e078.jpg" position="anchor" orientation="portrait"/><label>(18)</label></disp-formula>
</p><p>The value of F-measure is large only when both of <italic>p</italic> and <italic>r</italic> are high, and small when either of them is poor. This is appropriate for our objective of accurately predicting disease genes, as deficiencies in either precision or recall will be reflected by a low F-measure.</p></sec><sec id="s3c"><title>Experimental Results</title><sec id="s3c1"><title>Benchmarking of EPU ensemble learning algorithm against state-of-art techniques</title><p>First, we compared our EPU algorithm against four state-of-the-art techniques, namely, PUDI method <xref rid="pone.0097079-Yang2" ref-type="bibr">[13]</xref>, Smalter's method <xref rid="pone.0097079-Smalter1" ref-type="bibr">[10]</xref>, Xu's method <xref rid="pone.0097079-Xu1" ref-type="bibr">[15]</xref> and ProDiGe <xref rid="pone.0097079-Mordelet1" ref-type="bibr">[12]</xref>. <xref ref-type="table" rid="pone-0097079-t001">Table 1</xref> shows that our proposed EPU, on average, is 6.5%, 15.1%, 16.2% and 16.4% better than PUDI, ProDiGe, Smalter's method, Xu's method in terms of F-measure respectively. In particular, EPU can achieve much better precision and consistently better recall when compared against the recently proposed method PUDI. It shows that EPU can effectively extract hidden positive and negative data from the unlabeled data to boost classification performance.</p><table-wrap id="pone-0097079-t001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0097079.t001</object-id><label>Table 1</label><caption><title>Overall comparison of classification performance among different techniques.</title></caption><alternatives><graphic id="pone-0097079-t001-1" xlink:href="pone.0097079.t001"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup><thead><tr><td align="left" rowspan="1" colspan="1">Disease group</td><td align="left" rowspan="1" colspan="1">Techniques</td><td align="left" rowspan="1" colspan="1">Precision (p)</td><td align="left" rowspan="1" colspan="1">Recall (r)</td><td align="left" rowspan="1" colspan="1">F-measure (F)</td></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Cardiovascular</td><td align="left" rowspan="1" colspan="1">PUDI</td><td align="left" rowspan="1" colspan="1">82.0%</td><td align="left" rowspan="1" colspan="1">80.3%</td><td align="left" rowspan="1" colspan="1">80.4%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">ProDiGe</td><td align="left" rowspan="1" colspan="1">54.3%</td><td align="left" rowspan="1" colspan="1">96.3%</td><td align="left" rowspan="1" colspan="1">69.3%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Smalter's method</td><td align="left" rowspan="1" colspan="1">75.4%</td><td align="left" rowspan="1" colspan="1">67.6%</td><td align="left" rowspan="1" colspan="1">70.6%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Xu's method</td><td align="left" rowspan="1" colspan="1">72.1%</td><td align="left" rowspan="1" colspan="1">60.0%</td><td align="left" rowspan="1" colspan="1">65.4%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">EPU</td><td align="left" rowspan="1" colspan="1">85.2%</td><td align="left" rowspan="1" colspan="1">81.0%</td><td align="left" rowspan="1" colspan="1">
<bold>84.1%</bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">Endocrine</td><td align="left" rowspan="1" colspan="1">PUDI</td><td align="left" rowspan="1" colspan="1">83.6%</td><td align="left" rowspan="1" colspan="1">75.3%</td><td align="left" rowspan="1" colspan="1">79.2%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">ProDiGe</td><td align="left" rowspan="1" colspan="1">57.3%</td><td align="left" rowspan="1" colspan="1">87.7%</td><td align="left" rowspan="1" colspan="1">69.3%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Smalter's method</td><td align="left" rowspan="1" colspan="1">76.4%</td><td align="left" rowspan="1" colspan="1">58.8%</td><td align="left" rowspan="1" colspan="1">66.5%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Xu's method</td><td align="left" rowspan="1" colspan="1">75.4%</td><td align="left" rowspan="1" colspan="1">62.0%</td><td align="left" rowspan="1" colspan="1">68.0%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">EPU</td><td align="left" rowspan="1" colspan="1">88.1%</td><td align="left" rowspan="1" colspan="1">87.7%</td><td align="left" rowspan="1" colspan="1">
<bold>87.9%</bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">Neurological</td><td align="left" rowspan="1" colspan="1">PUDI</td><td align="left" rowspan="1" colspan="1">70.3%</td><td align="left" rowspan="1" colspan="1">80.1%</td><td align="left" rowspan="1" colspan="1">74.9%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">ProDiGe</td><td align="left" rowspan="1" colspan="1">63.1%</td><td align="left" rowspan="1" colspan="1">74.0%</td><td align="left" rowspan="1" colspan="1">68.1%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Smalter's method</td><td align="left" rowspan="1" colspan="1">60.6%</td><td align="left" rowspan="1" colspan="1">65.9%</td><td align="left" rowspan="1" colspan="1">63.1%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Xu's method</td><td align="left" rowspan="1" colspan="1">59.7%</td><td align="left" rowspan="1" colspan="1">66.7%</td><td align="left" rowspan="1" colspan="1">63.0%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">EPU</td><td align="left" rowspan="1" colspan="1">78.2%</td><td align="left" rowspan="1" colspan="1">80.4%</td><td align="left" rowspan="1" colspan="1">
<bold>78.6%</bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">Metabolic</td><td align="left" rowspan="1" colspan="1">PUDI</td><td align="left" rowspan="1" colspan="1">80.1%</td><td align="left" rowspan="1" colspan="1">84.8%</td><td align="left" rowspan="1" colspan="1">82.4%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">ProDiGe</td><td align="left" rowspan="1" colspan="1">58.7%</td><td align="left" rowspan="1" colspan="1">84.5%</td><td align="left" rowspan="1" colspan="1">69.3%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Smalter's method</td><td align="left" rowspan="1" colspan="1">59.1%</td><td align="left" rowspan="1" colspan="1">84.7%</td><td align="left" rowspan="1" colspan="1">69.6%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Xu's method</td><td align="left" rowspan="1" colspan="1">65.6%</td><td align="left" rowspan="1" colspan="1">78.3%</td><td align="left" rowspan="1" colspan="1">71.4%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">EPU</td><td align="left" rowspan="1" colspan="1">83.3%</td><td align="left" rowspan="1" colspan="1">93.9%</td><td align="left" rowspan="1" colspan="1">
<bold>90.9%</bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">Ophthalmological</td><td align="left" rowspan="1" colspan="1">PUDI</td><td align="left" rowspan="1" colspan="1">71.6%</td><td align="left" rowspan="1" colspan="1">78.5%</td><td align="left" rowspan="1" colspan="1">74.9%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">ProDiGe</td><td align="left" rowspan="1" colspan="1">58.3%</td><td align="left" rowspan="1" colspan="1">77.7%</td><td align="left" rowspan="1" colspan="1">66.6%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Smalter's method</td><td align="left" rowspan="1" colspan="1">56.7%</td><td align="left" rowspan="1" colspan="1">77.8%</td><td align="left" rowspan="1" colspan="1">65.5%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Xu's method</td><td align="left" rowspan="1" colspan="1">64.2%</td><td align="left" rowspan="1" colspan="1">71.3%</td><td align="left" rowspan="1" colspan="1">67.4%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">EPU</td><td align="left" rowspan="1" colspan="1">89.3%</td><td align="left" rowspan="1" colspan="1">81.0%</td><td align="left" rowspan="1" colspan="1">
<bold>84.7%</bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">Cancer</td><td align="left" rowspan="1" colspan="1">PUDI</td><td align="left" rowspan="1" colspan="1">76.3%</td><td align="left" rowspan="1" colspan="1">80.0%</td><td align="left" rowspan="1" colspan="1">78.0%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">ProDiGe</td><td align="left" rowspan="1" colspan="1">71.1%</td><td align="left" rowspan="1" colspan="1">79.8%</td><td align="left" rowspan="1" colspan="1">75.3%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Smalter's method</td><td align="left" rowspan="1" colspan="1">73.8%</td><td align="left" rowspan="1" colspan="1">79.0%</td><td align="left" rowspan="1" colspan="1">76.3%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Xu's method</td><td align="left" rowspan="1" colspan="1">71.0%</td><td align="left" rowspan="1" colspan="1">79.7%</td><td align="left" rowspan="1" colspan="1">75.1%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">EPU</td><td align="left" rowspan="1" colspan="1">81.2%</td><td align="left" rowspan="1" colspan="1">84.5%</td><td align="left" rowspan="1" colspan="1">
<bold>82.6%</bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">Average performance</td><td align="left" rowspan="1" colspan="1">PUDI</td><td align="left" rowspan="1" colspan="1">77.3%</td><td align="left" rowspan="1" colspan="1">79.8%</td><td align="left" rowspan="1" colspan="1">78.3%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">ProDiGe</td><td align="left" rowspan="1" colspan="1">60.5%</td><td align="left" rowspan="1" colspan="1">83.3%</td><td align="left" rowspan="1" colspan="1">69.7%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Smalter's method</td><td align="left" rowspan="1" colspan="1">67.0%</td><td align="left" rowspan="1" colspan="1">72.3%</td><td align="left" rowspan="1" colspan="1">68.6%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Xu's method</td><td align="left" rowspan="1" colspan="1">68.0%</td><td align="left" rowspan="1" colspan="1">69.7%</td><td align="left" rowspan="1" colspan="1">68.4%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">EPU</td><td align="left" rowspan="1" colspan="1">84.2%</td><td align="left" rowspan="1" colspan="1">84.8%</td><td align="left" rowspan="1" colspan="1">
<bold>84.8%</bold>
</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="nt101"><label/><p>PUDI is a SVM-based approach that partitions unlabeled genes into multiple levels with different associations to confirmed disease genes. ProDiGe is a bagging method that iteratively chooses random subsets from unlabeled subset and trains multiple classifiers. Smalter's method integrates multiple biological features, such as topological features, sequence-derived features, evolutionary age features. Xu's method employs the KNN classifier to predict disease genes.</p></fn></table-wrap-foot></table-wrap></sec><sec id="s3c2"><title>Comparison of EPU with base classifiers</title><p>Next, we compared the performance of our proposed EPU against its base classifiers MSVM, WNB, WKNN. As shown in <xref ref-type="table" rid="pone-0097079-t002">Table 2</xref>, on average, MSVM achieved the highest F-measure (81.3%), much higher than WNB (69.5%) and WKNN (68.7%). This is not surprising as MSVM can handle multiple weighted positive and negative sets when building its classification model. Furthermore, SVM is known to perform significantly better than NB and KNN in many real-world applications.</p><table-wrap id="pone-0097079-t002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0097079.t002</object-id><label>Table 2</label><caption><title>Overall comparison to single-expert classifiers.</title></caption><alternatives><graphic id="pone-0097079-t002-2" xlink:href="pone.0097079.t002"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup><thead><tr><td align="left" rowspan="1" colspan="1">Disease group</td><td align="left" rowspan="1" colspan="1">Techniques</td><td align="left" rowspan="1" colspan="1">Precision (<italic>p</italic>)</td><td align="left" rowspan="1" colspan="1">Recall (<italic>r</italic>)</td><td align="left" rowspan="1" colspan="1">F-measure (<italic>F</italic>)</td></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Cardiovascular</td><td align="left" rowspan="1" colspan="1">MSVM</td><td align="left" rowspan="1" colspan="1">74.3%</td><td align="left" rowspan="1" colspan="1">87.6%</td><td align="left" rowspan="1" colspan="1">80.4%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">WNB</td><td align="left" rowspan="1" colspan="1">57.3%</td><td align="left" rowspan="1" colspan="1">72.5%</td><td align="left" rowspan="1" colspan="1">63.9%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">WKNN(3)</td><td align="left" rowspan="1" colspan="1">60.1%</td><td align="left" rowspan="1" colspan="1">68.6%</td><td align="left" rowspan="1" colspan="1">64.0%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">EPU</td><td align="left" rowspan="1" colspan="1">85.2%</td><td align="left" rowspan="1" colspan="1">81.0%</td><td align="left" rowspan="1" colspan="1">
<bold>84.1%</bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">Endocrine</td><td align="left" rowspan="1" colspan="1">MSVM</td><td align="left" rowspan="1" colspan="1">83.4%</td><td align="left" rowspan="1" colspan="1">85.2%</td><td align="left" rowspan="1" colspan="1">84.2%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">WNB</td><td align="left" rowspan="1" colspan="1">61.3%</td><td align="left" rowspan="1" colspan="1">70.4%</td><td align="left" rowspan="1" colspan="1">65.3%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">WKNN(3)</td><td align="left" rowspan="1" colspan="1">64.5%</td><td align="left" rowspan="1" colspan="1">53.1%</td><td align="left" rowspan="1" colspan="1">57.9%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">EPU</td><td align="left" rowspan="1" colspan="1">88.1%</td><td align="left" rowspan="1" colspan="1">87.7%</td><td align="left" rowspan="1" colspan="1">
<bold>87.9%</bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">Neurological</td><td align="left" rowspan="1" colspan="1">MSVM</td><td align="left" rowspan="1" colspan="1">69.3%</td><td align="left" rowspan="1" colspan="1">83.7%</td><td align="left" rowspan="1" colspan="1">75.8%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">WNB</td><td align="left" rowspan="1" colspan="1">61.1%</td><td align="left" rowspan="1" colspan="1">74.4%</td><td align="left" rowspan="1" colspan="1">67.0%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">WKNN(3)</td><td align="left" rowspan="1" colspan="1">62.3%</td><td align="left" rowspan="1" colspan="1">67.1%</td><td align="left" rowspan="1" colspan="1">64.6%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">EPU</td><td align="left" rowspan="1" colspan="1">78.2%</td><td align="left" rowspan="1" colspan="1">80.4%</td><td align="left" rowspan="1" colspan="1">
<bold>78.6%</bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">Metabolic</td><td align="left" rowspan="1" colspan="1">MSVM</td><td align="left" rowspan="1" colspan="1">84.0%</td><td align="left" rowspan="1" colspan="1">91.3%</td><td align="left" rowspan="1" colspan="1">87.4%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">WNB</td><td align="left" rowspan="1" colspan="1">68.8%</td><td align="left" rowspan="1" colspan="1">79.9%</td><td align="left" rowspan="1" colspan="1">73.9%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">WKNN(3)</td><td align="left" rowspan="1" colspan="1">76.6%</td><td align="left" rowspan="1" colspan="1">78.8%</td><td align="left" rowspan="1" colspan="1">77.6%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">EPU</td><td align="left" rowspan="1" colspan="1">83.3%</td><td align="left" rowspan="1" colspan="1">93.9%</td><td align="left" rowspan="1" colspan="1">
<bold>90.9%</bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">Ophthalmological</td><td align="left" rowspan="1" colspan="1">MSVM</td><td align="left" rowspan="1" colspan="1">78.4%</td><td align="left" rowspan="1" colspan="1">86.1%</td><td align="left" rowspan="1" colspan="1">81.9%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">WNB</td><td align="left" rowspan="1" colspan="1">61.2%</td><td align="left" rowspan="1" colspan="1">78.7%</td><td align="left" rowspan="1" colspan="1">68.8%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">WKNN(3)</td><td align="left" rowspan="1" colspan="1">67.3%</td><td align="left" rowspan="1" colspan="1">72.2%</td><td align="left" rowspan="1" colspan="1">69.6%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">EPU</td><td align="left" rowspan="1" colspan="1">89.3%</td><td align="left" rowspan="1" colspan="1">81.0%</td><td align="left" rowspan="1" colspan="1">
<bold>84.7%</bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">Cancer</td><td align="left" rowspan="1" colspan="1">MSVM</td><td align="left" rowspan="1" colspan="1">73.4%</td><td align="left" rowspan="1" colspan="1">83.9%</td><td align="left" rowspan="1" colspan="1">78.3%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">WNB</td><td align="left" rowspan="1" colspan="1">72.5%</td><td align="left" rowspan="1" colspan="1">85.1%</td><td align="left" rowspan="1" colspan="1">78.3%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">WKNN(3)</td><td align="left" rowspan="1" colspan="1">76.4%</td><td align="left" rowspan="1" colspan="1">81.0%</td><td align="left" rowspan="1" colspan="1">78.6%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">EPU</td><td align="left" rowspan="1" colspan="1">81.2%</td><td align="left" rowspan="1" colspan="1">84.5%</td><td align="left" rowspan="1" colspan="1">
<bold>82.6%</bold>
</td></tr><tr><td align="left" rowspan="1" colspan="1">Average performance</td><td align="left" rowspan="1" colspan="1">MSVM</td><td align="left" rowspan="1" colspan="1">78.6%</td><td align="left" rowspan="1" colspan="1">86.3%</td><td align="left" rowspan="1" colspan="1">81.3%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">WNB</td><td align="left" rowspan="1" colspan="1">63.7%</td><td align="left" rowspan="1" colspan="1">76.8%</td><td align="left" rowspan="1" colspan="1">69.5%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">WKNN(3)</td><td align="left" rowspan="1" colspan="1">67.9%</td><td align="left" rowspan="1" colspan="1">70.1%</td><td align="left" rowspan="1" colspan="1">68.7%</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">EPU</td><td align="left" rowspan="1" colspan="1">84.2%</td><td align="left" rowspan="1" colspan="1">84.8%</td><td align="left" rowspan="1" colspan="1">
<bold>84.8%</bold>
</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="nt102"><label/><p>EPU is compared with its three component classifiers Multi-level Support Vector Machine (MSVM), Weighted Na&#x000ef;ve Bayes (WNB) and Weighted K-Nearest Neighbor (KNN) on 6 disease groups. WKNN(3) is an instance-based classifier that predicts the class of an unlabeled gene based on its 3 closest labeled genes.</p></fn></table-wrap-foot></table-wrap><p>Our proposed ensemble learning method EPU is able to achieve 84.8% in terms of F-measure, which is 3.5%, 15.3% and 16.1% better than MSVM, WNB and WKNN respectively. Moreover, EPU consistently outperformed all 3 component classifiers for every disease class. This strongly demonstrates that EPU can effectively integrate multiple classification models and minimize the overall error rate through dynamically assigning different weights to different classification models.</p></sec><sec id="s3c3"><title>Sensitivity study on the parameter &#x003b7; in EPU and parameter k in genetic similarity networks</title><p>We perform the sensitivity study for parameter <italic>&#x003b7;</italic> in EPU and coverage of genetic similarity networks. Parameter <italic>&#x003b7;</italic> is the learning rate in EPU algorithm. We perform EPU on six disease groups with <italic>&#x003b7;</italic> from 0.001 to 0.03. The result indicates that step size within 0.001 is small enough to move optimal value point in hypothesis space and our EPU is robust and stable when <italic>&#x003b7;</italic> is small (<xref ref-type="supplementary-material" rid="pone.0097079.s004">Table S3</xref> for the detailed results). In addition, we study the effect of the parameter <italic>k</italic> that determines the number of neighbors of each gene in biological networks. The results in <xref ref-type="supplementary-material" rid="pone.0097079.s005">Table S4</xref> show that EPU consistently achieved best performance with <italic>k</italic> in (1, 9).</p></sec><sec id="s3c4"><title>Comparing EPU with existing ensemble learning approaches</title><p>We also compared our proposed EPU with two existing ensemble approaches, majority vote and weighted majority vote <xref rid="pone.0097079-Kuncheva1" ref-type="bibr">[31]</xref>, in terms of F-measure across the six disease classes. EPU was shown to outperform the existing ensemble methods (see <xref ref-type="supplementary-material" rid="pone.0097079.s003">Table S2</xref> for the detailed results), indicating that our proposed EPU is a superior ensemble strategy for integrating multiple classification models for disease gene prediction.</p></sec><sec id="s3c5"><title>Predicting novel disease genes for disease groups</title><p>To demonstrate novel disease gene prediction using the EPU algorithm, we selected two important disease groups, namely, metabolic and cancer, as detailed case studies. For each target disease class, we obtained a set of confirmed disease genes from OMIM and GENECARD as the positive training set, and applied our proposed EPU algorithm to prioritize a novel disease gene from the unlabeled gene set.</p><p>We first applied our EPU algorithm to discover novel disease genes for metabolic diseases. 12 unlabeled genes were detected to be associated with target disease using our algorithm. For verification, we searched the literature for evidence that supports the association of these predicted disease genes to metabolic diseases. We found that two predicted genes, RHEB and DOK5, have indeed been reported to be associated with metabolic diseases. Rheb, a GTP-binding protein, was reported to be inactivated to protect cardiomyocyte during energy deprivation via activation of autophagy. This implies that RHEB is a key regulator of autophagy during myocardial ischemia, which has implications in patients with obesity and metabolic syndrome <xref rid="pone.0097079-Sciarretta1" ref-type="bibr">[32]</xref>. As for DOK5, Tabassum <italic>et al.</italic> identified that it is a novel candidate disease genes associated with type 2 diabetes, which is a metabolic disorder due to obesity <xref rid="pone.0097079-Tabassum1" ref-type="bibr">[33]</xref>.</p><p>Our EPU model also predicted 32 unlabeled genes as candidate genes associated with cancer. Seven of them, SIGLEC7, PRDX4, PRDX5, HNRNPL, SRPK1, ABCB10 and PHF10 have been reported to be associated with cancer diseases. <xref ref-type="table" rid="pone-0097079-t003">Table 3</xref> lists these candidate disease genes and the supporting literature evidence that we have found.</p><table-wrap id="pone-0097079-t003" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0097079.t003</object-id><label>Table 3</label><caption><title>Novel cancer-related genes predicted by EPU.</title></caption><alternatives><graphic id="pone-0097079-t003-3" xlink:href="pone.0097079.t003"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" span="1"/><col align="center" span="1"/></colgroup><thead><tr><td align="left" rowspan="1" colspan="1">Gene ID</td><td align="left" rowspan="1" colspan="1">Supported literatures</td></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">SUGLEC7</td><td align="left" rowspan="1" colspan="1">Ito A. et al. (2001) Binding specificity of siglec7 to disialogangliosides of renal cell carcinoma: possible role of disialogangliosides in tumor progression. FEBS Lett.</td></tr><tr><td align="left" rowspan="1" colspan="1">PRDX4</td><td align="left" rowspan="1" colspan="1">Lee S.U. et al. (2008) Involvement of peroxiredoxin IV in the 16alpha-hydroxyestrone-induced proliferation of human MCF-7 breast cancer cells. Cell Biol Int 32(4): 401&#x02013;5.</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Park H.J. et al. (2008) Proteomic profiling of endothelial cells in human lung cancer. J Proteome Res 7(3):1138&#x02013;50.</td></tr><tr><td align="left" rowspan="1" colspan="1">PRDX5</td><td align="left" rowspan="1" colspan="1">Enqman L., et al. (2003) Thioredoxin reductase and cancer cell growth inhibition by organotellurium compounds that could be selectively incorporated into tumor cells. Bioorg Med Chem 11(23): 5091&#x02013;100.</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">McNaughton M., et al. (2004) Cyclodextrin-derived diorganyl tellurides as glutathione peroxidase mimics and inhibitors of thioredoxin reductase and cancer cell growth. J Med Chem 47(1): 233&#x02013;9.</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Enqman L., et al. (2000) Water-soluble organotellurium compounds inhibit thioredoxin reductase and the growth of human cancer cells. Anticancer Drug Des. 15(5): 323&#x02013;30.</td></tr><tr><td align="left" rowspan="1" colspan="1">HNRNPL</td><td align="left" rowspan="1" colspan="1">Goehe, R.W., et al. (2010) hnRNPL regulates the tumorigenic capacity of lung cancer xenografts in mice via caspase-9 pre-mRNA processing. J. Clin. Inves. 120(11): 3923.</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Hope N.R., et al. (2011) The expression profile of RNA-binding proteins in primary and metastatic colorectal cancer: relationship of heterogeneous nuclear ribonucleoproteins with prognosis. Hum Pathol. 42(3): 393&#x02013;402.</td></tr><tr><td align="left" rowspan="1" colspan="1">SRPK1</td><td align="left" rowspan="1" colspan="1">Hayes, G.M., et al. (2007) Serine-arginine protein kinase 1 overexpression is associated with tumorigenic imbalance in mitogen-activated protein kinase pathways in breast, colonic, and pancreatic carcinomas. Cancer Res. 67(5): 2972&#x02013;80.</td></tr><tr><td align="left" rowspan="1" colspan="1">ABCB10 PHF10</td><td align="left" rowspan="1" colspan="1">Tang, L., et al. (2009) Exclusion of ABCB8 and ABCB10 as cancer candidate genes in acute myeloid leukemiaLetter to the Editor. Leukemia 23: 1000&#x02013;2.</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Wet M., et al. (2010) Preparation of PHF10 antibody and analysis of PHF10 expression gastric cancer tissues. Journal of Xiao Bao Yu Fen Zi Mian Yi Xue 26(9): 874&#x02013;6.</td></tr><tr><td align="left" rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">Li C., et al. (2012) MicroRNA-409-3p regulates cell proliferation and apoptosis by targeting PHF10 in gastric cancer. Cancer Lett 320(2): 187&#x02013;97.</td></tr><tr><td align="left" rowspan="1" colspan="1">SUGLEC7</td><td align="left" rowspan="1" colspan="1">Ito A. et al. (2001) Binding specificity of siglec7 to disialogangliosides of renal cell carcinoma: possible role of disialogangliosides in tumor progression. FEBS Lett.</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="nt103"><label/><p>EPU is used to discover novel cancer related genes from unlabeled gene set. The table list 12 candidate genes associated with cancer and their corresponding literature evidences.</p></fn></table-wrap-foot></table-wrap><p>For other candidate cancer genes without literature evidence support, seven of them, PMM1, SRCIN1, ISY1, KDM4A, CIR1, PPP2R5A and NOL3 have been shown to associate with cancer diseases in GO similarity network, GE similarity network and PPI network. From GO similarity network, PMM1 is one of top 5 nearest neighbours of cancer disease gene PPM1D and SCRIN1 is one of neighbours of disease gene CTNNB1. In GE similarity network, ISY1 is linked to disease gene P2RX7, KDM4A and CIR1 are interacted with disease genes CTNNB1 and MSH2 respectively, indicating that three suspicious genes are highly correlated with cancer disease genes in terms of gene expression. From PPI network, PPP2R5A is directly interacted with two disease genes, BCL2 and TP53, and NOL3 is linking to two disease genes, BAX and CASP8.</p></sec></sec></sec><sec id="s4"><title>Conclusions and Discussion</title><p>Despite the considerable progress in disease gene discovery, there are still many unknown disease genes that are yet to be characterized. Machine learning methods can be used to predict novel disease genes from the confirmed disease genes, based on the observation that genes associated with similar disease phenotypes are likely to share similar biological characteristics. However, there are two challenging issues for disease gene predictions. Firstly, how to leverage various biological sources during our model building process, which could effectively alleviate the bias issues from the incompleteness and noise in the data. Secondly, how to integrate multiple computational models to minimize the potential bias and errors as individual learning methods has their inherent limitations and they could predict accurately for some disease genes but could fail badly for the other ones. In this work, we have designed a novel ensemble learning method EPU for predicting disease genes via using a network-based random walk with restart approach on multiple biological networks, and an ensemble classification approach on multiple machine-learned prediction models. By using multiple biological data sources, EPU is less susceptible to potential bias, incompleteness and noise in individual data source. In this paper, we choose Nearest Neighbor, Na&#x000ef;ve Bayes and SVM as three base learning models of EPU due to three reasons: they are the state-of-the-art learning techniques that have been widely used in disease gene identification filed <xref rid="pone.0097079-Smalter1" ref-type="bibr">[10]</xref>
<xref rid="pone.0097079-Radivojac1" ref-type="bibr">[11]</xref>
<xref rid="pone.0097079-Xu1" ref-type="bibr">[15]</xref>
<xref rid="pone.0097079-Linghu1" ref-type="bibr">[17]</xref>
<xref rid="pone.0097079-Palaniappan1" ref-type="bibr">[34]</xref>; 2) we are combining PU learning models instead of traditional classification models &#x02013; we choose the three classification models as they can be easily adapted to build PU learning models; 3) they are quite diverse with learning criterions, so that their complementary nature may contribute a more accurate and robust combinational result. By employing an ensemble approach for prediction, EPU also minimizes the inherent limitations of individual prediction models. Finally, by employing PU learning techniques for building its ensemble of classification models, EPU is able to treat the unknown genes appropriately as an unlabeled set <italic>U</italic> (instead of a negative set <italic>N</italic>) for training, thereby resulting in more robust predictions. Experimental evaluations have confirmed the effectiveness of our proposed approach, with our EPU method consistently performing much better than the existing state-of-the-art techniques for disease gene prediction on six disease classes.</p><p>As more biological data sources and machine learning classifiers become available in the future, our EPU method can be an effective framework to integrate the additional biological and computational resources for better disease gene predictions. For further work, we will explore the inclusion of other biological data sources for disease gene prediction using our framework. Given that many machine learning problems in biomedical research do involve ensemble Positive Unlabeled data, we can also adapt our EPU framework to other applications, such as drug-target interaction prediction <xref rid="pone.0097079-Mei1" ref-type="bibr">[35]</xref>
<xref rid="pone.0097079-Mei2" ref-type="bibr">[36]</xref>.</p></sec><sec sec-type="supplementary-material" id="s5"><title>Supporting Information</title><supplementary-material content-type="local-data" id="pone.0097079.s001"><label>Figure S1</label><caption><p>Procedure of extracting candidate positive set.</p><p>(DOCX)</p></caption><media xlink:href="pone.0097079.s001.docx"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0097079.s002"><label>Table S1</label><caption><p>Number of disease genes associated with six disease classes.</p><p>(DOCX)</p></caption><media xlink:href="pone.0097079.s002.docx"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0097079.s003"><label>Table S2</label><caption><p>Performance comparison of ensemble methods.</p><p>(DOCX)</p></caption><media xlink:href="pone.0097079.s003.docx"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0097079.s004"><label>Table S3</label><caption><p>Effect of parameter &#x003b7; on classification performance of six disease groups.</p><p>(DOCX)</p></caption><media xlink:href="pone.0097079.s004.docx"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0097079.s005"><label>Table S4</label><caption><p>Sensitive analysis on biological network noise to disease gene prediction.</p><p>(DOCX)</p></caption><media xlink:href="pone.0097079.s005.docx"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec></body><back><ref-list><title>References</title><ref id="pone.0097079-LpezBigas1"><label>1</label><mixed-citation publication-type="journal">
<name><surname>L&#x000f3;pez-Bigas</surname><given-names>N</given-names></name>, <name><surname>Ouzounis</surname><given-names>CA</given-names></name> (<year>2004</year>) <article-title>Genome-wide identification of genes likely to be involved in human genetic disease</article-title>. <source>Nucleic Acids Research</source>
<volume>32(10)</volume>: <fpage>3108</fpage>&#x02013;<lpage>3114</lpage>.<pub-id pub-id-type="pmid">15181176</pub-id></mixed-citation></ref><ref id="pone.0097079-Yang1"><label>2</label><mixed-citation publication-type="journal">
<name><surname>Yang</surname><given-names>P</given-names></name>, <name><surname>Li</surname><given-names>X</given-names></name>, <name><surname>Wu</surname><given-names>M</given-names></name>, <name><surname>Kwoh</surname><given-names>CK</given-names></name>, <name><surname>Ng</surname><given-names>SK</given-names></name> (<year>2011</year>) <article-title>Inferring Gene-Phenotype Associations via Global Protein Complex Network Propagation</article-title>. <source>PLoS ONE</source>
<volume>6(7)</volume>: <fpage>e21502</fpage>.<pub-id pub-id-type="pmid">21799737</pub-id></mixed-citation></ref><ref id="pone.0097079-Ala1"><label>3</label><mixed-citation publication-type="journal">
<name><surname>Ala</surname><given-names>U</given-names></name>, <name><surname>Piro</surname><given-names>RM</given-names></name>, <name><surname>Grassi</surname><given-names>E</given-names></name>, <name><surname>Damasco</surname><given-names>C</given-names></name>, <name><surname>Silengo</surname><given-names>L</given-names></name>, <etal>et al</etal> (<year>2008</year>) <article-title>Prediction of Human Disease Genes by Human-Mouse Conserved Coexpression Analysis</article-title>. <source>PLoS Comput Biol</source>
<volume>4(3)</volume>: <fpage>e1000043</fpage>.<pub-id pub-id-type="pmid">18369433</pub-id></mixed-citation></ref><ref id="pone.0097079-Ideker1"><label>4</label><mixed-citation publication-type="journal">
<name><surname>Ideker</surname><given-names>T</given-names></name>, <name><surname>Sharan</surname><given-names>R</given-names></name> (<year>2008</year>) <article-title>Protein networks in disease</article-title>. <source>Genome Research</source>
<volume>18</volume>: <fpage>644</fpage>&#x02013;<lpage>652</lpage>.<pub-id pub-id-type="pmid">18381899</pub-id></mixed-citation></ref><ref id="pone.0097079-PerezIratxeta1"><label>5</label><mixed-citation publication-type="journal">
<name><surname>Perez-Iratxeta</surname><given-names>C</given-names></name>, <name><surname>Bork</surname><given-names>P</given-names></name>, <name><surname>Andrade</surname><given-names>MA</given-names></name> (<year>2002</year>) <article-title>Association of genes to genetically inherited diseases using data mining</article-title>. <source>Nature Genetics</source>
<volume>313</volume>: <fpage>316</fpage>&#x02013;<lpage>319</lpage>.</mixed-citation></ref><ref id="pone.0097079-Goh1"><label>6</label><mixed-citation publication-type="journal">
<name><surname>Goh</surname><given-names>KI</given-names></name>, <name><surname>Cusick</surname><given-names>ME</given-names></name>, <name><surname>Valle</surname><given-names>D</given-names></name>, <name><surname>Childs</surname><given-names>B</given-names></name>, <name><surname>Vidal</surname><given-names>M</given-names></name>, <etal>et al</etal> (<year>2007</year>) <article-title>The human disease network</article-title>. <source>Proc Natl Acad Sci USA</source>
<volume>104(21)</volume>: <fpage>8685</fpage>&#x02013;<lpage>8690</lpage>.<pub-id pub-id-type="pmid">17502601</pub-id></mixed-citation></ref><ref id="pone.0097079-Brunner1"><label>7</label><mixed-citation publication-type="journal">
<name><surname>Brunner</surname><given-names>HG</given-names></name>, <name><surname>Van Driel</surname><given-names>MA</given-names></name> (<year>2004</year>) <article-title>From syndrome families to functional genomics</article-title>. <source>Nat Rev Genet</source>
<volume>5(7)</volume>: <fpage>545</fpage>&#x02013;<lpage>551</lpage>.<pub-id pub-id-type="pmid">15211356</pub-id></mixed-citation></ref><ref id="pone.0097079-Vanunu1"><label>8</label><mixed-citation publication-type="journal">
<name><surname>Vanunu</surname><given-names>O</given-names></name>, <name><surname>Magger</surname><given-names>O</given-names></name>, <name><surname>Ruppin</surname><given-names>E</given-names></name>, <name><surname>Shlomi</surname><given-names>T</given-names></name>, <name><surname>Sharan</surname><given-names>R</given-names></name> (<year>2010</year>) <article-title>Associating Genes and Protein Complexes with Disease via Network Propagation</article-title>. <source>Plos computational biology</source>
<volume>6(1)</volume>: <fpage>e1000641</fpage>.<pub-id pub-id-type="pmid">20090828</pub-id></mixed-citation></ref><ref id="pone.0097079-Adie1"><label>9</label><mixed-citation publication-type="journal">
<name><surname>Adie</surname><given-names>EA</given-names></name>, <name><surname>Adams</surname><given-names>RR</given-names></name>, <name><surname>Evans</surname><given-names>KL</given-names></name>, <name><surname>Porteous</surname><given-names>DJ</given-names></name>, <name><surname>Pickard</surname><given-names>B</given-names></name> (<year>2005</year>) <article-title>Speeding disease gene discovery by sequence based candidate prioritization</article-title>. <source>BMC Bioinformatics</source>
<volume>6(1)</volume>: <fpage>55</fpage>.<pub-id pub-id-type="pmid">15766383</pub-id></mixed-citation></ref><ref id="pone.0097079-Smalter1"><label>10</label><mixed-citation publication-type="other">Smalter A, Lei SF, Chen X (2007) Human Disease-gene Classification with Integrative Sequence-based and Topological Features of Protein-protein Interaction Networks. BIBM.</mixed-citation></ref><ref id="pone.0097079-Radivojac1"><label>11</label><mixed-citation publication-type="journal">
<name><surname>Radivojac</surname><given-names>P</given-names></name>, <name><surname>Peng</surname><given-names>K</given-names></name>, <name><surname>Clark</surname><given-names>WT</given-names></name>, <name><surname>Peters</surname><given-names>BJ</given-names></name>, <name><surname>Mohan</surname><given-names>A</given-names></name>, <etal>et al</etal> (<year>2008</year>) <article-title>An integrated approach to inferring gene-disease associations in humans</article-title>. <source>Proteins</source>
<volume>72(3)</volume>: <fpage>1030</fpage>&#x02013;<lpage>1037</lpage>.<pub-id pub-id-type="pmid">18300252</pub-id></mixed-citation></ref><ref id="pone.0097079-Mordelet1"><label>12</label><mixed-citation publication-type="journal">
<name><surname>Mordelet</surname><given-names>F</given-names></name>, <name><surname>Vert</surname><given-names>JP</given-names></name> (<year>2011</year>) <article-title>ProDiGe: Prioritization Of Disease Genes with multitask machine learning from positive and unlabeled examples</article-title>. <source>BMC Bioinformatics</source>
<volume>12(1)</volume>: <fpage>389</fpage>.<pub-id pub-id-type="pmid">21977986</pub-id></mixed-citation></ref><ref id="pone.0097079-Yang2"><label>13</label><mixed-citation publication-type="journal">
<name><surname>Yang</surname><given-names>P</given-names></name>, <name><surname>Li</surname><given-names>XL</given-names></name>, <name><surname>Mei</surname><given-names>JP</given-names></name>, <name><surname>Kwoh</surname><given-names>CK</given-names></name>, <name><surname>Ng</surname><given-names>SK</given-names></name> (<year>2012</year>) <article-title>Positive-unlabeled learning for disease gene identification</article-title>. <source>Bioinformatics</source>
<volume>28(20)</volume>: <fpage>2640</fpage>&#x02013;<lpage>2647</lpage>.<pub-id pub-id-type="pmid">22923290</pub-id></mixed-citation></ref><ref id="pone.0097079-Liu1"><label>14</label><mixed-citation publication-type="other">Liu T, Du X, Xu YD, Li M, Wang X (2011) Partially Supervised Text Classification with Multi-Level Examples. In AAAI.</mixed-citation></ref><ref id="pone.0097079-Xu1"><label>15</label><mixed-citation publication-type="journal">
<name><surname>Xu</surname><given-names>JZ</given-names></name>, <name><surname>Li</surname><given-names>YJ</given-names></name> (<year>2006</year>) <article-title>Discovering disease-genes by topological features in human protein&#x02013;protein interaction network</article-title>. <source>Bioinformatics</source>
<volume>22(22)</volume>: <fpage>2800</fpage>&#x02013;<lpage>2805</lpage>.<pub-id pub-id-type="pmid">16954137</pub-id></mixed-citation></ref><ref id="pone.0097079-Khler1"><label>16</label><mixed-citation publication-type="journal">
<name><surname>K&#x000f6;hler</surname><given-names>S</given-names></name>, <name><surname>Bauer</surname><given-names>S</given-names></name>, <name><surname>Horn</surname><given-names>D</given-names></name>, <name><surname>Robinson</surname><given-names>PN</given-names></name> (<year>2008</year>) <article-title>Walking the interactome for prioritization of candidate disease genes</article-title>. <source>The American Journal of Human Genetics</source>
<volume>82(4)</volume>: <fpage>949</fpage>&#x02013;<lpage>958</lpage>.<pub-id pub-id-type="pmid">18371930</pub-id></mixed-citation></ref><ref id="pone.0097079-Linghu1"><label>17</label><mixed-citation publication-type="journal">Linghu B, Snitkin ES, Hu Z, Xia Y, DeLisi C (2009) Genome-wide prioritization of disease genes and identification of disease-disease associations from an integrated human functional linkage network. Genome Biology <volume>10(9)</volume>: R91+.</mixed-citation></ref><ref id="pone.0097079-Schlicker1"><label>18</label><mixed-citation publication-type="journal">
<name><surname>Schlicker</surname><given-names>A</given-names></name>, <name><surname>Lengauer</surname><given-names>T</given-names></name>, <name><surname>Albrecht</surname><given-names>M</given-names></name> (<year>2010</year>) <article-title>Improving disease gene prioritization using the semantic similarity of Gene Ontology terms</article-title>. <source>Bioinformatics</source>
<volume>26(18)</volume>: <fpage>i561</fpage>&#x02013;<lpage>i567</lpage>.<pub-id pub-id-type="pmid">20823322</pub-id></mixed-citation></ref><ref id="pone.0097079-Prasad1"><label>19</label><mixed-citation publication-type="journal">
<name><surname>Prasad</surname><given-names>TK</given-names></name>, <name><surname>Goel</surname><given-names>R</given-names></name>, <name><surname>Kandasamy</surname><given-names>K</given-names></name>, <name><surname>Keerthikumar</surname><given-names>S</given-names></name>, <name><surname>Kumar</surname><given-names>S</given-names></name>, <etal>et al</etal> (<year>2009</year>) <article-title>Human Protein Reference Database</article-title>. <source>Nucleic Acids Research</source>
<volume>37</volume>: <fpage>767</fpage>&#x02013;<lpage>772</lpage>.</mixed-citation></ref><ref id="pone.0097079-Brown1"><label>20</label><mixed-citation publication-type="journal">
<name><surname>Brown</surname><given-names>KR</given-names></name>, <name><surname>Jurisica</surname><given-names>I</given-names></name> (<year>2005</year>) <article-title>Online predicted human interaction database</article-title>. <source>Bioinformatics</source>
<volume>21(9)</volume>: <fpage>2076</fpage>&#x02013;<lpage>2082</lpage>.<pub-id pub-id-type="pmid">15657099</pub-id></mixed-citation></ref><ref id="pone.0097079-Gene1"><label>21</label><mixed-citation publication-type="journal">
<collab>Gene Ontology Consortium</collab> (<year>2004</year>) <article-title>The gene ontology database and informatics resource</article-title>. <source>Nucleic Acid Res</source>
<volume>32(1)</volume>: <fpage>258</fpage>&#x02013;<lpage>261</lpage>.</mixed-citation></ref><ref id="pone.0097079-Wang1"><label>22</label><mixed-citation publication-type="journal">
<name><surname>Wang</surname><given-names>JZ</given-names></name>, <name><surname>Du</surname><given-names>Z</given-names></name>, <name><surname>Payattakool</surname><given-names>R</given-names></name>, <name><surname>Philip</surname><given-names>SY</given-names></name>, <name><surname>Chen</surname><given-names>CF</given-names></name> (<year>2007</year>) <article-title>A new method to measure the semantic similarity of GO terms</article-title>. <source>Bioinformatics</source>
<volume>23(10)</volume>: <fpage>1274</fpage>&#x02013;<lpage>1281</lpage>.<pub-id pub-id-type="pmid">17344234</pub-id></mixed-citation></ref><ref id="pone.0097079-McKusick1"><label>23</label><mixed-citation publication-type="journal">
<name><surname>McKusick</surname><given-names>VA</given-names></name> (<year>2007</year>) <article-title>Mendelian Inheritance in Man and Its Online Version, OMIM</article-title>. <source>Am. J. Hum. Genet</source>. <volume>80</volume>: <fpage>588</fpage>&#x02013;<lpage>604</lpage>.<pub-id pub-id-type="pmid">17357067</pub-id></mixed-citation></ref><ref id="pone.0097079-VanDriel1"><label>24</label><mixed-citation publication-type="journal">
<name><surname>Van Driel</surname><given-names>MA</given-names></name>, <name><surname>Bruggeman</surname><given-names>J</given-names></name>, <name><surname>Vriend</surname><given-names>G</given-names></name>, <name><surname>Brunner</surname><given-names>HG</given-names></name>, <name><surname>Leunissen</surname><given-names>JA</given-names></name> (<year>2006</year>) <article-title>A text-mining analysis of the human phenome</article-title>. <source>European Journal of Human Genetics</source>
<volume>14(5)</volume>: <fpage>535</fpage>&#x02013;<lpage>542</lpage>.<pub-id pub-id-type="pmid">16493445</pub-id></mixed-citation></ref><ref id="pone.0097079-Flicek1"><label>25</label><mixed-citation publication-type="journal">
<name><surname>Flicek</surname><given-names>P</given-names></name>, <name><surname>Amode</surname><given-names>MR</given-names></name>, <name><surname>Barrel</surname><given-names>D</given-names></name> (<year>2011</year>) <article-title>Ensemble 2011</article-title>. <source>Nucleic Acids Res</source>
<volume>39(S1)</volume>: <fpage>800</fpage>&#x02013;<lpage>806</lpage>.</mixed-citation></ref><ref id="pone.0097079-Deza1"><label>26</label><mixed-citation publication-type="other">Deza E, Deza MM (2009) Encyclopedia of Distances. Springer Berline Heidelberg.</mixed-citation></ref><ref id="pone.0097079-LOVSZ1"><label>27</label><mixed-citation publication-type="journal">
<name><surname>LOV&#x000c1;SZ</surname><given-names>L</given-names></name> (<year>1993</year>) <article-title>Random walks on graphs: a survey</article-title>. <source>Combinatorics: Paul Erd&#x000f6;s is Eighty</source>
<volume>2</volume>: <fpage>1</fpage>&#x02013;<lpage>46</lpage>.</mixed-citation></ref><ref id="pone.0097079-Vapnik1"><label>28</label><mixed-citation publication-type="other">Vapnik V (1998) Statistical Learning Theory. Wiley, New York.</mixed-citation></ref><ref id="pone.0097079-Chang1"><label>29</label><mixed-citation publication-type="journal">
<name><surname>Chang</surname><given-names>C</given-names></name>, <name><surname>Lin</surname><given-names>C</given-names></name> (<year>2011</year>) <article-title>LIBSVM: a library for support vector machines</article-title>. <source>ACM Trans Intell Syst Technol</source>
<volume>2(3)</volume>: <fpage>27</fpage>.</mixed-citation></ref><ref id="pone.0097079-Mitchell1"><label>30</label><mixed-citation publication-type="other">Mitchell TM (1997) Artificial neural network. Machine Learning 81&#x02013;127.</mixed-citation></ref><ref id="pone.0097079-Kuncheva1"><label>31</label><mixed-citation publication-type="other">Kuncheva LI (2004). Combining pattern classifiers: methods and algorithms. John Wiley &#x00026; Sons.</mixed-citation></ref><ref id="pone.0097079-Sciarretta1"><label>32</label><mixed-citation publication-type="journal">
<name><surname>Sciarretta</surname><given-names>S</given-names></name>, <name><surname>Zhai</surname><given-names>P</given-names></name>, <name><surname>Shao</surname><given-names>D</given-names></name>, <name><surname>Maejima</surname><given-names>Y</given-names></name>, <name><surname>Robbins</surname><given-names>J</given-names></name>, <etal>et al</etal> (<year>2012</year>) <article-title>Rheb is a critical regulator of autophagy during myocardial ischemia: pathophysiological implications in obesity and metabolic syndrome</article-title>. <source>Circulation</source>
<volume>125(9)</volume>: <fpage>1134</fpage>&#x02013;<lpage>1146</lpage>.<pub-id pub-id-type="pmid">22294621</pub-id></mixed-citation></ref><ref id="pone.0097079-Tabassum1"><label>33</label><mixed-citation publication-type="journal">
<name><surname>Tabassum</surname><given-names>R</given-names></name>, <name><surname>Mahajan</surname><given-names>A</given-names></name>, <name><surname>Chauhan</surname><given-names>G</given-names></name>, <name><surname>Dwivedi</surname><given-names>OP</given-names></name>, <name><surname>Ghosh</surname><given-names>S</given-names></name>, <etal>et al</etal> (<year>2010</year>) <article-title>Evaluation of DOK5 as a susceptibility gene for type 2 diabetes and obesity in North Indian population</article-title>. <source>BMC Medical Genetics</source>
<volume>11</volume>: <fpage>35</fpage>.<pub-id pub-id-type="pmid">20187968</pub-id></mixed-citation></ref><ref id="pone.0097079-Palaniappan1"><label>34</label><mixed-citation publication-type="other">Palaniappan S, Awang R (2008) Intelligent heart disease prediction system using data mining techniques. In Computer Systems and Applications, 2008. AICCSA 2008. IEEE/ACS International Conference pp.108&#x02013;115.</mixed-citation></ref><ref id="pone.0097079-Mei1"><label>35</label><mixed-citation publication-type="journal">
<name><surname>Mei</surname><given-names>JP</given-names></name>, <name><surname>Kwoh</surname><given-names>CK</given-names></name>, <name><surname>Yang</surname><given-names>P</given-names></name>, <name><surname>Li</surname><given-names>XL</given-names></name>, <name><surname>Zheng</surname><given-names>J</given-names></name> (<year>2013</year>) <article-title>Drug&#x02013;target interaction prediction by learning from local information and neighbors</article-title>. <source>Bioinformatics</source>
<volume>29(2)</volume>: <fpage>238</fpage>&#x02013;<lpage>245</lpage>.<pub-id pub-id-type="pmid">23162055</pub-id></mixed-citation></ref><ref id="pone.0097079-Mei2"><label>36</label><mixed-citation publication-type="other">Mei JP, Kwoh CK, Yang P, Li XL, Zheng J (2012). Globalized bipartite local model for drug-target interaction prediction. In Proceedings of the 11th International Workshop on Data Mining in Bioinformatics. pp. 8&#x02013;14.</mixed-citation></ref></ref-list></back></article>